<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon shortcut" type="image/png" href="https://blog.ubie.tech/logo.png"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&amp;display=swap"/><title>yoheikikuta | Ubie Engineers&#x27; Blogs</title><meta property="og:title" content="yoheikikuta"/><meta property="og:url" content="https://blog.ubie.tech/members/yoheikikuta"/><meta name="twitter:card" content="summary_large_image"/><meta property="og:site" content="Ubie Engineers&#x27; Blogs"/><meta property="og:image" content="https://blog.ubie.tech/og.png"/><link rel="canonical" href="https://blog.ubie.tech/members/yoheikikuta"/><link rel="preload" href="/_next/static/css/5b1e5c056c67d836f701.css" as="style"/><link rel="stylesheet" href="/_next/static/css/5b1e5c056c67d836f701.css" data-n-g=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-8a83f0fd99327c4684a8.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.1daf1ec1ecf144ee9147.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.8d61253ae98ee51657b8.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-49079e3278dd6cef7229.js" as="script"/><link rel="preload" href="/_next/static/chunks/81b50c7ab23905e464b4340eb234bd6ea389d26b.5863e0c3fa35c0c78394.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/members/%5Bid%5D-f279413a3daf3c18264d.js" as="script"/></head><body><div id="__next"><header class="site-header"><div class="content-wrapper"><div class="site-header__inner"><a class="site-header__logo-link" href="/"><img src="/logo.png" alt="Ubie Engineers&#x27; Blogs" class="site-header__logo-img"/><span class="site-header__logo-text">Ubie<br/>Engineers&#x27; Blogs</span></a><div class="site-header__links"><a href="https://ubie.life/" class="site-header__link" target="_blank">Company</a><a href="https://recruit.ubie.life/jd_dev" class="site-header__link" target="_blank">Recruit</a></div></div></div></header><section class="member"><div class="content-wrapper"><header class="member-header"><div class="member-header__avatar"><img src="/avatars/yoheikikuta.jpg" alt="yoheikikuta" width="100" height="100" class="member-header__avatar-img"/></div><h1 class="member-header__nickname">yoheikikuta</h1><p class="member-header__real-name">Yohei Kikuta</p><p class="member-header__bio">learning machine learning</p><div class="member-header__links"><a href="https://twitter.com/yohei_kikuta" class="member-header__link"><img src="/icons/twitter.svg" alt="Twitterのユーザー@yohei_kikuta" width="22" height="22"/></a><a href="https://github.com/yoheikikuta" class="member-header__link"><img src="/icons/github.svg" alt="GitHubのユーザー@yoheikikuta" width="22" height="22"/></a><a href="https://github.com/yoheikikuta/resume" class="member-header__link"><img src="/icons/link.svg" alt="ウェブサイトのリンク" width="22" height="22"/></a></div></header><div class="member-posts-container"><div class="post-list"><article class="post-link"><a class="post-link__author" href="/members/yoheikikuta/"><img src="/avatars/yoheikikuta.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">yoheikikuta</div><time dateTime="2021-11-13T00:00:00.000Z" class="post-link__date">9 days ago</time></div></a><a href="https://yoheikikuta.github.io/BigQuery_tips_part1/" class="post-link__main-link"><h2 class="post-link__title">BigQuery を使って分析する際の tips (part1)</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=yoheikikuta.github.io" width="14" height="14" class="post-link__site-favicon"/>yoheikikuta.github.io</div></a></article><article class="post-link"><a class="post-link__author" href="/members/yoheikikuta/"><img src="/avatars/yoheikikuta.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">yoheikikuta</div><time dateTime="2021-10-26T00:00:00.000Z" class="post-link__date">a month ago</time></div></a><a href="https://yoheikikuta.github.io/casual_talk_launchable/" class="post-link__main-link"><h2 class="post-link__title">Launchable の人とカジュアル面談した</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=yoheikikuta.github.io" width="14" height="14" class="post-link__site-favicon"/>yoheikikuta.github.io</div></a></article><article class="post-link"><a class="post-link__author" href="/members/yoheikikuta/"><img src="/avatars/yoheikikuta.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">yoheikikuta</div><time dateTime="2021-10-01T00:00:00.000Z" class="post-link__date">2 months ago</time></div></a><a href="https://yoheikikuta.github.io/ml_design_book/" class="post-link__main-link"><h2 class="post-link__title">施策デザインのための機械学習入門 を読んだ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=yoheikikuta.github.io" width="14" height="14" class="post-link__site-favicon"/>yoheikikuta.github.io</div></a></article><article class="post-link"><a class="post-link__author" href="/members/yoheikikuta/"><img src="/avatars/yoheikikuta.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">yoheikikuta</div><time dateTime="2021-05-19T00:00:00.000Z" class="post-link__date">6 months ago</time></div></a><a href="https://yoheikikuta.github.io/my_purpose_of_DS_and_ML/" class="post-link__main-link"><h2 class="post-link__title">自分がデータ分析/機械学習で成し遂げたいこと</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=yoheikikuta.github.io" width="14" height="14" class="post-link__site-favicon"/>yoheikikuta.github.io</div></a></article><article class="post-link"><a class="post-link__author" href="/members/yoheikikuta/"><img src="/avatars/yoheikikuta.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">yoheikikuta</div><time dateTime="2021-05-02T00:00:00.000Z" class="post-link__date">7 months ago</time></div></a><a href="https://yoheikikuta.github.io/lookback_on_hikifunefm/" class="post-link__main-link"><h2 class="post-link__title">hikifunefm 反省会会場</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=yoheikikuta.github.io" width="14" height="14" class="post-link__site-favicon"/>yoheikikuta.github.io</div></a></article><article class="post-link"><a class="post-link__author" href="/members/yoheikikuta/"><img src="/avatars/yoheikikuta.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">yoheikikuta</div><time dateTime="2021-02-22T00:00:00.000Z" class="post-link__date">9 months ago</time></div></a><a href="https://yoheikikuta.github.io/GAS_local_development_env/" class="post-link__main-link"><h2 class="post-link__title">clasp と TypeScript で GAS の開発環境を整えた備忘録</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=yoheikikuta.github.io" width="14" height="14" class="post-link__site-favicon"/>yoheikikuta.github.io</div></a></article><article class="post-link"><a class="post-link__author" href="/members/yoheikikuta/"><img src="/avatars/yoheikikuta.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">yoheikikuta</div><time dateTime="2020-12-30T00:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://yoheikikuta.github.io/Summary2020/" class="post-link__main-link"><h2 class="post-link__title">2020年のまとめ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=yoheikikuta.github.io" width="14" height="14" class="post-link__site-favicon"/>yoheikikuta.github.io</div></a></article><article class="post-link"><a class="post-link__author" href="/members/yoheikikuta/"><img src="/avatars/yoheikikuta.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">yoheikikuta</div><time dateTime="2020-12-29T00:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://yoheikikuta.github.io/book_I_read_in_2020/" class="post-link__main-link"><h2 class="post-link__title">2020年に読んだ本を一言コメントと共に振り返る</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=yoheikikuta.github.io" width="14" height="14" class="post-link__site-favicon"/>yoheikikuta.github.io</div></a></article><article class="post-link"><a class="post-link__author" href="/members/yoheikikuta/"><img src="/avatars/yoheikikuta.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">yoheikikuta</div><time dateTime="2020-11-27T00:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://yoheikikuta.github.io/work_from_home_environment/" class="post-link__main-link"><h2 class="post-link__title">在宅作業環境</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=yoheikikuta.github.io" width="14" height="14" class="post-link__site-favicon"/>yoheikikuta.github.io</div></a></article><article class="post-link"><a class="post-link__author" href="/members/yoheikikuta/"><img src="/avatars/yoheikikuta.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">yoheikikuta</div><time dateTime="2020-10-30T00:00:00.000Z" class="post-link__date">a year ago</time></div></a><a href="https://yoheikikuta.github.io/working_log_using_jasper/" class="post-link__main-link"><h2 class="post-link__title">Jasper による（データ分析系）タスクの作業ログ管理</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=yoheikikuta.github.io" width="14" height="14" class="post-link__site-favicon"/>yoheikikuta.github.io</div></a></article></div></div></div></section><footer class="site-footer"><div class="content-wrapper"><p>© <!-- -->Ubie Discovery</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"member":{"id":"yoheikikuta","nickname":"yoheikikuta","realName":"Yohei Kikuta","bio":"learning machine learning","avatarSrc":"/avatars/yoheikikuta.jpg","sources":["https://yoheikikuta.github.io/feed.xml"],"twitterUsername":"yohei_kikuta","githubUsername":"yoheikikuta","websiteUrl":"https://github.com/yoheikikuta/resume"},"postItems":[{"title":"BigQuery を使って分析する際の tips (part1)","contentSnippet":"TL;DRBigQuery で分析する際の tips をまとめてみる。長くなりそうなのでいくつかに分割して書くpart1 はエディタとして何を使うかとか実行結果の連携などについて書くBigQuery console/DataGrip を使いつつ、結果を GitHub issues/Google Sheets/Bdash Server で共有するという感じで使っている仕事で BigQuery を使って分析することが多いので、いくつかの回に分けて BigQuery を使って分析する際の tips をまとめていくことにする。今回は part1 としてエディタとして何を使うかとか実行結果の連携などについて書く。個人的な探索的・アドホック分析用途の話に限定して、組織的にどういうデータ分析基盤を使うかとかそういう話はしない（会社だと ETL の L として dbt https://www.getdbt.com/ を使っていて、これについても色々と書きたいことはあるけどそれはまた別の機会に）。tips1: クエリを書くためのエディタ基本的には BigQuery console https://console.cloud.google.com/bigquery を使ってきたし、今でも使っている。しかしながら、これは BigQuery console を使っている人全員が感じていることだと思うが、イマイチと言わざるを得ない。ブラウザで提供してるので補完が遅いのはやむなしと思う（この遅さによって書いてる時にちょくちょくスムースにいかなくてストレスが溜まることもあるが）けど、フォーマッターはとりあえずこれで納得するかというレベルにならない（CASE 式を見るたびに足が震えてしまう）し、ちょっと前に新 UI が出た時も「これは本当に開発者が触って使い心地チェックしてるのだろうか？」という感じだった（同僚の中には使いづらいのでエディタタブを無効にしているという人もいる）。BigQuery は間違いなく素晴らしいプロダクトではあるが、その「プロダクト」には UI の観点があまり含まれていないようで、こういうところは残念である。もちろんいいところもたくさんあって、ブラウザがあれば使えるというお手軽さは最高だし、実行前の検査でクエリスキャン量を表示したりや文法エラーに留まらずより広範囲のエラーを教えてくれたり（例えば異なる region にある dataset のテーブルを join は不可能だが、それをクエリ実行前に教えてくれる）、Google Sheets や GCS への export などがシームレスに実行できる点、など重宝している。個人的にはフォーマッターがマシになってくれてかつそのフォーマッターが公開されてくれれば、BigQuery console 一本でやっていくという選択肢を取ってもいいかなと思っているが、待ち続けてもそういう日がやって来る気配はない。そんなこんなで JetBrains 社の DataGrip https://www.jetbrains.com/datagrip/ も併用している。これはデータベース IDE で JetBrains 社の製品！という感じの rich な機能を提供してくれる。書き味はざっくりこんな感じ。FROM 句書く時に謎の空白行を入れてるけど、これはテーブル名の変換候補の表示で会社で使っている project/dataset/table が見えないようにするためです。JetBranins 社製品だけあって、補完の滑らかさはかなり心地良い。その他にも文を複数書いてもよしなに各文を解釈してくれるので CMD + Enter とカーソル選択のみで特定の文を選択的に実行できるとか、F1 で Quick Documentation してテーブルの概要を把握できるとか、Export Data でクエリ結果を markdown table にして Copy to Clickboard して GitHub issues に貼れるとか、便利な機能が多い。フォーマッター Editor \u003e Code Style \u003e SQL \u003e General で実際にどのようにフォーマットされるのかの例が以下のように視覚的に分かりやすい形で柔軟に色々と設定することができる（フォーマッターとかあれこれ細かく設定したくないのでこれ使っとけばだいたいオッケーというものをチームで使うようにしたいのだが…）。DataGrip は色々なデータソースに対応していて、BigQuery 対応は比較的最近（2020.2）始まったので、まだまだ不完全な部分もある。やはり Array型 とか STRUCT型 周りが弱い感じがする。補完が弱いのはまあそんなに気にならないが、手元で色々分析する時に例えば id だけ入れ替えれば使いまわせるような scripting statements https://cloud.google.com/bigquery/docs/reference/standard-sql/scripting を使ったりするので、これがサポートされてないのはちょっと不便だ。それと JetBrains 社製品ということでそこそこの金額がするのも気になるところ。会社で働いていてがっつり使うという場合は問題ないが、そんなに頻度高くなく必要になったらちょっと使いたいくらいの場合はなかなか購入まで踏み切りづらいかもしれない。local でのクエリの保存とちょっとしたグラフを見るという用途で Bdash https://github.com/bdash-app/bdash も使っている。local での保存という意味では別に Bdash を使わなくてもいいのだが、後述するように Bdash Server https://github.com/bdash-app/bdash-server で他の人にクエリを共有するというのにも便利なので Bdash を使っている。作者が社内にいるのでなんかサポートされてない機能があったら feature request を出せるのも便利（contribute しろよという意見は一旦無視する）。tips2: Colaboratory での利用クエリだけでなく、Python で例えば pandas.DataFrame に結果を読み込んで interactive に色々分析したいということもある。ちょっとした分析が目的のときには local に環境準備をするのは面倒だし、他の人に再現可能な形で共有するのにも適してない。そういうときにはやはり Colaboratory https://colab.research.google.com/notebooks/welcome.ipynb を使うのは便利である。BigQuery にクエリを投げて結果を利用する方法はいくつかあるが、一番お手軽なのは magic commands を使うことだろう。自分は以下のコードを snippets に登録して使えるようにしている。from google.colab import authauth.authenticate_user()%%bigquery --project [適当な GCP project] dfselect * from ``これで interactive に authentification をして、クエリ実行結果を df という pandas.DataFrame に格納することができる。Colaboratory は URL を共有してコピーして使ってもらえば他の人も（自分と同じような環境構築をしてもらうとかの手間がなく）簡単に利用できる。ちなみに自分がいま分析してる範囲だとそんなに Python を使ってあれこれ分析せずに SQL だけで十分なことも多いので、そんなに使ってはいない。ちょっと話は逸れるが、分析やモデリング周りを一手に担う統合プラットフォームとして Vertex AI https://cloud.google.com/vertex-ai が実際どんな感じかはやや気になっている。ここまで色々揃っていると、このプラットフォームに沿うように自分たちがうまく振る舞わないといけないと思うが、そうしたときにどれくらいのメリットを享受できるのかというのはガッツリ運用している人がいればぜひ聞いてみたいところだ。tips3: 実行結果の連携方法分析結果をどう連携するかについても日々実践していることを書いてみる。一番頻度高く使うのは、クエリの実行結果を作業ログとしての GitHub issues に markdown table として貼るというもの。これは連携というよりは自分の日々の作業ログであったり他の人が作業ログを見た時に自分の思考の流れが追えるようにしてるという側面が強い（ちなみに以前データ分析系タスクの作業ログ共有に Jasper を使っているという話 https://yoheikikuta.github.io/working_log_using_jasper/ も書いたりしている）。markdown table としてコピーする方法は BigQuery なら以下のように tweet した方法を使っていて、DataGrip の場合は Export Data で Copy to Clickboard を使っている（当然後者の方が使いやすい）。BQ console のクエリ結果をコピーして GitHub issues とかにマークダウンとしてペーストできるのは便利だけど、左だとヘッダーがちゃんととれなくて右だと大丈夫（これは Safari で Chrome だと見た目の違いは分からない）tips は左上からではなく右下の値のところから範囲選択することです（真顔） pic.twitter.com/Th3h99C5Qt— Yohei KIKUTA (@yohei_kikuta) November 7, 2021 次によく使うのは Google Sheets に結果を export して連携するというもの。Google Sheets はソフトウェアエンジニア以外でも使える人が多いので、結果を共有したり interactive にちょっと触ってもらうのには適している。BigQuery console だと 結果の保存 \u003e Google スプレッドシート でスッと export できるし、DataGrip ならば Export Data で TSV にして Copy to Clickboard でコピーしてから Google Sheets にペーストしている。ちょっとダルいのは、特に前者の方法だと個人の Google Drive に保存されてそのままでは他の人が使えないので、共有できるよう保存場所を移動するなりしないといけないという点。Google Sheets という意味では Connected Sheets https://cloud.google.com/bigquery/docs/connected-sheets を使うのも便利。単純にクエリの結果を貼って共有するのとは違い、こちらはちょっとしたクエリを書いてその実行結果を Google Sheets 上で扱えるというのが利点で、さらに定期実行を設定できるので新しいデータを参照してもらうことができる。自分はちょっとした分析結果を使ってビジネス的な意思決定のインプットにしてもらう、とかいうときに日時で新しい結果を参照できるような Connected Sheets を共有したりする。もちろんこの Connected Sheets 上で複雑なクエリを書いたり、あれもこれもとやりすぎると管理や運用が大変になってくるので、よく使うし重要というものはちゃんとデータマートを準備したり BI ツールで閲覧できるようにしたりなどと交通整理する必要はある。Data Portal とか BI tool での連携というのはアドホックというよりもう少しかっちり運用という感じになるので、今回は対象外としておく。連携というほどにはまだ会社全体で使い倒してるレベルにはないが、Bdash Server が導入されてるのでクエリと結果を共有（というか他の人も見れたら便利かもなというものを見れるとこに置いておくだけという感じ）するときに使っている。Bdash からワンクリックで以下のように共有できるので、local での自分用のクエリ保存と簡単なグラフ確認を Bdash でして、それを他の人も共有できるように Bdash Server にも送っておくという使い方をしている。まとめBigQuery で分析する際の part1 としてエディタとして何を使うかとか実行結果の連携などについて書いた。","link":"https://yoheikikuta.github.io/BigQuery_tips_part1/","isoDate":"2021-11-13T00:00:00.000Z","dateMiliSeconds":1636761600000,"authorName":"yoheikikuta","authorId":"yoheikikuta"},{"title":"Launchable の人とカジュアル面談した","contentSnippet":"TL;DR興味があったので Launchable の @yoshiori さん @draftcode さんとカジュアル面談をしたテストをはじめとしてソフトウェアエンジニアリングの生産性をデータドリブンで改善していくというのはめちゃ面白そう自分は現段階では転職意思がないけど、機械学習エンジニアで興味ある人は言ってくれればおつなぎします！Ubie Discovery に転職して一年半が過ぎた。そんな折に Launchable https://www.launchableinc.com/ で Machine Learning Engineer の position を募集しているというを見て、yoshiroi さんが転職した会社だし面白そうなので話を聞いてみたいなと思って連絡したら、転職の意思があまりないと事前に伝えていたにも関わらず快諾してもらった。現時点では自分が転職するということはないが、興味ある人もいるだろうということでブログに残しておく。（話の内容をブログにしてもよいというのはすでに先方に確認を取っています）経緯書いた通りだが、思い立って連絡したら一時間ほど話をしてもらえることになった。最近入社した @draftcode さんも呼んでもらって三人で話をすることになった。自分としても面白そうだと思っていた分野なので、話の前に HP を見て紹介されていた https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45861.pdf や https://engineering.fb.com/2018/11/21/developer-tools/predictive-test-selection/ やちょっとググって関連知識を調べるくらいはしておいた。Launchable の会社全般的な話会社の目指すところはデータドリブンでソフトウェアエンジニアリングの生産性を上げるというもので、その最初の取り組みとして特にテストに注力しているとのことらしい。ソフトウェアエンジニアリングはどのように不確実性と向き合うかというのを積み上げてきてはいるが、その中には確率的に判断せざるを得ないものもあるし、そうなると適切にデータを集めて統計的に考え行動する必要があると思う。そういったところに真正面から取り組んでいる Launchable の目的には共感する。ビジネスモデルは toB 向けのフリーミアムモデルで、HP の pricing を見るとなかなか面白くて、$7 / hours saved ということで開発が効率的になった分だけお金を支払うというものになっているらしい。マーケットはソフトウェア開発をしている企業全般ということになるのでポテンシャルはとても大きい。とはいえ会社ごとに違いはありますよね？という疑問が思い浮かぶので聞いてみたが、会社ごとにセットアップしてサービスを展開してきて、色々な勘所が分かってきたという段階らしい。カスタマイズを要求されまくって破綻するみたいなことはなさそうな一方で、もっとスケールさせるためにはまだまだアイデアやチャレンジが必要そう、みたいな印象。最近優秀なソフトウェアエンジニアの人が続々入社してる会社なので、一緒に働く同僚から得られる刺激が多そうなのもよさそう。Launchable の機械学習周りの話機械学習周りの話も色々と聞いてみた。ファイルの変更行数などを入力特徴量として、各テストの fail する確率を予測する GBDT を使うというのが基本になっているらしい。テスト実行を積み重ねることによってそこから単なる 成功/失敗 以上の情報を抽出するという試みは興味深い方向性だ。同じ会社でもレポジトリによって触る人が全然違うし、テストは複数レポジトリにまたがることもあるので、モデルを学習する単位としては一連のテストを実行するプロジェクト単位で作っているとのこと。ソフトウェアエンジニアリングに造詣がありつつも軸足は機械学習にある、というタイプの人がマッチしそう。ということで、Launchable は機械学習エンジニア絶賛募集中とのことです！ソフトウェアエンジニアは採用が順調だけど、機械学習エンジニアはなかなか path がないとのことだったので、私からも宣伝しておきます。もちろん一番は Ubie Discovery に興味を持って話を聞かせてくださいというのを期待しますが、Ubie Discovery よりも Launchable の方が興味があるんや！という場合も遠慮なく言ってください。ちなみに拠点は JP と US だけど、開発拠点は日本が中心とのことです。菊田さんぜひ！というありがたいお言葉もいただきましたが、自分の興味関心から考えるとやはり Ubie だなという気持なので、何か状況が変わるタイミングがあったりしたらまた話をさせていただきたい、という感じでカジュアル面談は着地しました。まとめ興味があったので Launchable の話を聞いてみたら面白そうだったのでブログに書いてみた。ちなみにあわよくば話をした二人とも Ubie Discovery に引っ張ってこようとして話の最中にどんどんこちらの話もねじ込んだのですが、さすがに転職するという雰囲気はありませんでした。ベンチャー企業同士仲良くやっていきましょう！","link":"https://yoheikikuta.github.io/casual_talk_launchable/","isoDate":"2021-10-26T00:00:00.000Z","dateMiliSeconds":1635206400000,"authorName":"yoheikikuta","authorId":"yoheikikuta"},{"title":"施策デザインのための機械学習入門 を読んだ","contentSnippet":"TL;DR機械学習に基づく施策をサービス改善につなげるためのフレームワークとその実践を提供してくれる本統一的なフレームワークと一貫した記述で、よく書かれている本だなと感心した個人的には 4.2 節の Implicit Feedbak を用いたバイアスを考慮したランキングシステムの構築のところは勉強になったタイトルの通り 施策デザインのための機械学習入門 という本を読んだ。本の正式なタイトルは「施策デザインのための機械学習入門　データ分析技術のビジネス活用における正しい考え方」というもの。本のタイトルからは具体的ににどういう内容が書いてるかは想像しにくいが、内容は機械学習に基づく施策を実際に導入する際に重要となる観点を一連のフレームワークとして提供し、そのフレームワークに基づいた具体的な実践を解説するというものになっている。技術評論社出版で HP は https://gihyo.jp/book/2021/978-4-297-12224-9 にある。https://github.com/ghmagazine/ml_design_book にある。本の概要章立ては以下のようになっている。1 章 機械学習実践のためのフレームワーク    KPI 設定 → データの観測構造をモデル化する → 解くべき問題を特定する → 観測データを用いて解くべき問題を近似する → 機械学習モデルを学習する → 施策を導入する というフレームワークを導入2 章 機械学習実践のための基礎技術    広告配信を例に導入したフレームワークに則って施策導入までの一連の流れを解説3 章 Explicit Feedbackに基づく推薦システムの構築    ユーザの行動に基づくデータの観測構造に注意を払って適切な目的関数を導く一連の流れと実験結果を解説4 章 Implicit Feedbackに基づくランキングシステムの構築    ポジションバイアス、セレクションバイアス、クリックノイズ、に対して適切な目的関数を導く一連の流れと実験結果を解説5 章 因果効果を考慮したランキングシステムの構築    より発展的な内容として推薦枠非経由の conversion も考慮したケースを紹介演習問題    本の内容を自分で実践に活かすための訓練となるような問題大まかな頭出しについてはこれより詳しいものとして著者のブログ https://usaito.hatenablog.com/entry/2021/08/03/191339 があるので、もう少し詳しく知りたい人はこれを読んでから本を買うかどうか決めればよさそう。全体的によく書けていて、入門書を謳って基本的なところから始まりつつも内容が割としっかりしていて、自分にとっても勉強になるところが多い本だった。推薦システムは 5 年くらい前に仕事でやって以来そんなに追ってなくてほとんど覚えてないこともあり、特に 4.2 節の Implicit Feedbak を用いたバイアスを考慮したランキングシステムの構築のところとかは勉強になった。数学的な定式化がしっかり目になされているので読みやすい。特によく書けているなと感じたところこのエントリではそれぞれの章でどういうことを書いてあるかを紹介したりはせず、自分が特によく書けているなと感じたところを書く。全編を通して一貫したフレームワークに基づく記述1 章で導入する機械学習実践のためのフレームワークに基づいた一貫した記述がなされている点がよい。本を書こうとすると、どうしても色々な知識を紹介しようとしてあれこれと詰め込み、結果として知識の羅列を薄く繋いだものになりがちだと思う。この本はそうではなくて、様々な具体的ケースに対応できる適度なレベルに抽象化したフレームワークを構築し、それで一本筋が通っている状態で個々の具体例を解説している。具体例で経験を積み、このフレームワークに立ち戻って理解を増強することで、より困難な他の具体例に立ち向かうことができるようになるという設計になっている。こういう思想は巻末の演習問題にも顕著に現れている。この統一的な記述は著者のこだわりというか信念が感じられてとてもよい。データの観測構造のモデル化と unbiased な目的関数の導出手順フレームワークの中でも特によいと感じたのがデータの観測構造のモデル化と 解くべき問題を近似するときの unbiased な目的関数を導出するところである。データの観測構造のモデル化のところは解析可能な数学的表現で対象の状況をモデル化するという意味合いが強い。この部分がしっかり目に書かれているのがよいところで、ここがきちんとモデル化できないと解くべき問題を数学的に表現できず、バイアスなどの落とし穴に気づくこともできない。（数学的表現に慣れてない人がこの本で機械学習に入門するぞ、という場合には少し難しいかもしれない）。データの観測構造をモデル化できるからこそ、解くべき問題を近似して適切な目的関数を設定するという後のプロセスも適切に実施できる。この本ではまずは観測データのみに注目してデータの観測構造を意識していないナイーブ推定量を算出し、それだとデータの観測構造に基づくバイアスが乗っているのでそれを是正するように Inverse Propensity Score 推定量（バイアスを打ち消すような重みを逆数として掛ける）を使いましょうという流れになっている。これを何度も繰り返すので、どうやって適切に解くべき問題を近似するのかというのが意識しやすくなっている。手計算できる簡単な例で感覚を掴む問題の本質を損なわないようにしつつ手計算で確認できる例が豊富にあるのもよい。ある種のアイデアがあるときに、それを正しく把握するためには（本質を損なわない）簡単な例でチェックするというのは重要で、そこを意識して簡単化した例がいくつも載せられている。簡単な例で振る舞いを理解する、次元解析をする、極端なケースで振る舞いを確認する、まずは生データを眺める（EDA する）、などは感覚を掴むために重要なので、実データで取り組む前に簡単だが重要な例があるのはよいと思った。余談だが、こういう話を書くと「いかにして問題をとくか」が思い出されるわけだが、これの機械学習/データ分析特化版みたいなのがあっても面白いかもしれない（断片的には色々なところで語られていると思うけど）。実験用データを問題設定に合わせて適宜いじっているオープンデータを使って実験する際に、本の内容を解説するために適宜手を加えてデータセット（本では半人工データと呼んでいる）を準備しているのも工夫が感じられた。機械学習の本を読んでると、それでは具体例と言ってこのデータにこのモデルを適用したら結果はこう！みたいな感じでそこから何かを得るということがあまりないことも多いが、本の内容を適切にサポートするような実験設定にしてあるところは素敵だなと思った。その他記述が丁寧すぎる部分がある。入門書ということなので丁寧にしたのだと思うけど、unbiased な目的変数の期待値が望み通りになっているかの計算がほぼ自明なのに繰り返し記述されてるのとかは、本書を通読できる人なら必要ないと感じた。もう少し記述をスキップした上で、章末の発展的内容を一部解説してみたり 5 章の内容で著者が考えてることをもっと深く記述してもらうとかだと個人的には嬉しかった。notation がちょっと confusing な部分がある。4.2 節の Pair Result Randomization のところで確率的ランキングを導入するが、ユーザ \\(j\\) に提示するランキング \\(y_j\\) にさらに \\(k \\leftrightarrow k+1\\) を swap するランキングと元のランキングという新しい次元の情報が出てくる。それらを断りなく \\(y_1, y_2\\) と書いたりするのでユーザの添字と confusing なところがある。まあこれはさらに新しい notation を導入したりすると複雑になりすぎるし分かるやろってことでそう書いてるのだと感じたけど、ちょっと読み淀んだ。あと \\(y^{-1}\\) でアイテムを指すのはあまりしっくりこなかったけど、推薦システム関連だとよく使われる notation なのかな。この本に限らずだけど、typo とか見つけたらフィードバックしたいけど、どこで受け付けてるか書いてくれると嬉しい。正誤表 https://gihyo.jp/assets/files/book/2021/978-4-297-12224-9/download/%E6%AD%A3%E8%AA%A4%E8%A1%A82021-08-18.pdf にないところだと図 4.5 の \\(R(u,i_9) = 0\\) でなく \\(R(u,i_9) = 1\\) というのがあった（本文を読めば分かるので単なる typo）。GitHub repository はコードだけって感じだったので書いていいか判断つかず、技術評論社のお問い合わせページ https://gihyo.jp/site/inquiry/book?ISBN=978-4-297-12224-9 に送っておいた。ただこちらは他の人が何送ってるかが見えないので被ったりしそう。GitHub repository あるなら issues にそういうフィードバックどうぞと案内するとよさそうか。まとめ施策デザインのための機械学習入門 を読んだ。よい本だったので書評ブログを書いたが、改めてブログとして書いてみると、著者が多大な努力を払って本を完成させたことが伺え、ありがとうございますという気持ち。","link":"https://yoheikikuta.github.io/ml_design_book/","isoDate":"2021-10-01T00:00:00.000Z","dateMiliSeconds":1633046400000,"authorName":"yoheikikuta","authorId":"yoheikikuta"},{"title":"自分がデータ分析/機械学習で成し遂げたいこと","contentSnippet":"TL;DRUbie 株式会社に入社して一年くらい経ったので振り返りをする改めてデータ分析/機械学習で何がしたいのかを考えているが、自分はデータから普遍的な知識を得たい人間で、その観点では（まだまだ先は長いけど）やりたいことができている人によって目的は色々だと思ういますが、みなさんはどうですか？Ubie 株式会社に入社して 1 年以上経過したので軽く振り返りをしつつ、そもそも自分はデータ分析/機械学習で何がしたいんだっけというのを改めて言語化してみるエントリ。ここしばらくは採用の文脈以外で他の会社の人と話すことが少なくて物足りないところもあるので、自分はこうだな〜という意見があればぜひ教えてください。一年間を振り返ってみるまず何よりも、勤続一年一ヶ月を達成している自分を褒めたい。凄いぞ自分。偉いぞ自分。勤続一年一ヶ月という圧倒的事実が示唆しているように、（労働の辛さはもちろんあるのだが）楽しく働けている。これは主観的にもそうだし、他の人から言われることもあるので客観的にもそうだと言えるだろう。入社を決めた時のブログエントリ https://yoheikikuta.github.io/joinning_ubie/ を今一度読んでみると、「ストーリーを語りたくなるような仕事ができそう」ということで入社を決めている。どうですか、ストーリー、語れそうですか？（自分への問いかけ）これに関しては力強く YES という回答なのだが、まだまだ「俺たちの戦いはこれからだ！」という状況なので、先を見据えつつも今やるべきことを着実に進めている。入社してしばらくは地道なバグの調査・修正とかデータの確認とかでしんどいタスクも結構あったのだが、そういうところをある程度乗り越え、今は有用なデータを蓄積することにフォーカスしつつ同時にそれを活用するというフェーズになっている。有用なデータを蓄積することは楽しい。簡単化した例として P(頭痛|髄膜炎) という条件付き確率を求めることを考えてみる。これは髄膜炎という病気に罹っているときに頭痛という症状を発症する確率を算出することを意味している。医学的な知識がない人にはこの一つの例であっても想像も難しいレベルだろう。医師であれば髄膜炎において頭痛は典型的な症状であって高い確率で発現することを知っているが、定量的に表現するということは簡単ではない（一人の医師が見聞きできる症例は限られているし、膨大にある症状と疾患の組み合わせを定量的に表現することは困難である）。十分な量のデータがあれば、髄膜炎に罹っている患者全体のデータから頭痛症状有りの患者の割合を求めることでこの条件付き確率を求めることができる。シンプルだが、シンプルであるが故に、データを集めるだけで医師の専門知識を誰にでも利用できる普遍的な知識へと昇華することができる。実際には、そもそものデータの真正性とか、年齢や性別による差異とか、既往歴や他の症状との関係性とか、気にすべき観点やより現実に即した発展は山のようにある。まだまだ先は長いが、こういったところを自分たちでデザインして進めていくのは実に楽しい。入社してから気付いた良さとして、一緒に働く機会がなかなかない業種である医師と同じチームで働けるという点が挙げられる。自分がほとんど触れてこなかった知識体系について造詣が深い専門家と一緒に働くと新鮮な驚きがあって楽しい。体調が悪い時に専門家に相談できるというのも優れた福利厚生と言える。福利厚生と言ってるが、社内医師が善意で相談に乗ってくれているという話で、これは仕事とは直接関係ないプログラミングの問題についてプログラマが答えてくれるようなもの。自分は胃痛でピロリ菌感染疑いだったとき、とりあえず自分で近場のクリニックに行ったら治療方針がよく分からずイマイチだったが、社内医師に相談しつつクリニックを変えたらあっさりと治療ができた。医師の専門性などを把握して適切な医療機関にかかるというのは簡単ではないなと実感したので、テクノロジーで人々を適切な医療に案内する、やっていきたいね。その他にも組織全体に関する業務や採用なども頑張っているが、これは同僚がたくさん情報発信してるので割愛。いいことばかりを書いたが、満足してないこともある。自分はデータ分析や機械学習の技術的に進んだ領域にも興味があるが、そういうところはこれまで殆どできていない。仕事とは別で摂取するしかないなと思って hikifune.fm を始めて補完していた。ただ、データが集まり人も集まり、この点に関しても色々なことに挑戦できそうな土台ができてきたので、今後は業務でもやっていけそう！自分はデータ分析/機械学習で何を成し遂げたいのかやってきた仕事を振り返りつつ、改めてデータ分析/機械学習を通じて何がしたいのかと考えてみると、自分はデータから普遍的な知識を抽出したいという嗜好性が高い。働き始めのころは今よりも数理的なモデリングへの興味が強く、現実のデータでモデルを作ってそこから意味のある情報を得ることに注力していた。仕事としてそれを実現するために、モデリング業務を中心に担当してサービスを改善・開発し、一部の内容は論文化したりと頑張っていた。こういう仕事はやっているとき楽しいと思っていたし、仕事始めのほぼ何も知らなかったところから考えると、相当に色々なことを学ぶこともできた。しかしながら、この手の仕事を続けていくうちに、自分は本当に何か普遍的な知識を得たのだろうか？という疑問を抱くようになってきた。発展的なモデルを駆使することでインパクトの大きな成果を出したり新しいサービスが作れたりする可能性は広がるけど、自分の人生の第一義的な目的はそういうものではないと知った。やはり入力となるデータに普遍的な知識を抽出できるポテンシャルがある領域が望ましい。そういった知識を積み上げることで、人類の知的財産に少しでも貢献できたな！という自己満足が得たいのである。一方で、可能なら労働なんてしたくないので金銭的にも十分なリターン（うまくいけば 5~10 年後には賃金のための労働をしなくてもいい）も欲しい。自分はビジネスで大成功するような才覚はないし、ライフプラン的にも給与所得だけでは難しさもあるので、期待値でいえば成長可能性が高い会社で Stock Option をもらうのが一番よさそう。こういった諸々の条件を満足し得る会社がどれくらいあるのか知らないが、自分が知る限り最も良い会社が Ubie 株式会社だった（偉そうに言ってるが @masa_kazama に声をかけてもらったおかげで知った。感謝）。前述の通り医療データには自分が望むポテンシャルが大いにあるし、会社として大きく成長する可能性も秘めている。当然どちらもうまくいくかの不確実性はまだまだ高いわけだけど、自分たちの力でそれを現実のものにしていこうと一丸となってやっていけるのは楽しい。もっと頑張っていきたいですね！たまにはこうやって「自分はそもそも何がやりたいんだっけ」を振り返ってみるのも一興ですね。ということで、みなさんはどうですか？ここまで自分の話をしてきたが、これは徹頭徹尾自分の好みであって、何が偉いとかどれが正しいとかこうあるべきとかいうものでは決してない。何を人生の目的関数とするかは人それぞれなので。ただし、目的関数に応じて適切な場所で働いた方がよいし、目的関数は時間と共に変わり得るものなのでその変化は認めて追従していった方がよい。例えば、機械学習を用いることで初めて実現可能となるようなサービスを作りたいと思っている人がいるとする。その人が日々の仕事ではまず機械学習を使わなくても済む方法を考えているとか、機械学習と関係のないコーディングがメインになっているとかいう状況であれば、目的とマッチしていないので環境を変えた方がいいだろう。データ分析や機械学習を活かしてサービスを改善したりビジネス的に大きな成果を出したいという人は、データの規模とかそれを効果的に使えるようなビジネスをしている会社に所属した方がいいだろう。このタイプの人は、入りはデータ分析や機械学習であってもやっていくうちに手法にはそんなに拘りがなくなって何でもやる人になるという印象がある。大学や研究所だけでなく企業でも研究職がそこそこあるので、研究を生業としてやっていきたいという人は他分野よりはやりやすそうだ。ただ、機械学習分野は参加人数が多くてカンファレンスに論文を通すために考慮しなければならない点も多いので、職業研究者がどうやって自分が本当にやりたい研究に取り組めるよう工夫をしているかは聞いてみたいところ。Kaggle のようなコンペ形式のデータ分析/機械学習が楽しいからそれに打ち込む、というのは目的が明瞭だし継続性もあってよさそう。多くの人が参加してその副次的な価値（コンペで得られた知見は直接関係のない仕事にも有用）を示してきた結果、仕事としても取り組めるような環境も出てきたのはいい話だな〜と思う。色々な目的関数があると思うので、どういう目的関数でそれを実現するためにいまどこで何をしてるか、というのはぜひ聞いてみたいですね。一年以上にも渡り他の会社の人と話す機会がなかなかなくて寂しいので、自分はこうだというのがある人は教えて欲しい〜。自分と似た考えの人で、Ubie 株式会社に興味がある人はお気軽にお声がけください。自分と似た考えじゃなくてもオッケーです。つまり興味があれば誰でも！！！まとめ仕事を振り返りつつ自分がデータ分析/機械学習で何を成し遂げたいのかを言語化してみた。自分はデータから普遍的な知識を得たいと思って今の会社で働いているけど、みなさんはどうですか？","link":"https://yoheikikuta.github.io/my_purpose_of_DS_and_ML/","isoDate":"2021-05-19T00:00:00.000Z","dateMiliSeconds":1621382400000,"authorName":"yoheikikuta","authorId":"yoheikikuta"},{"title":"hikifunefm 反省会会場","contentSnippet":"TL;DR15 回ほど配信をしたのでここらで hikifune.fm の振り返りをしてみる配信ドリブンで色々勉強したのでそこそこためになったし、シリーズ物はやってみて結構よかった二人で収録するメリットはあまり感じられなかったので今後どうするかは考え中hikifune.fm https://anchor.fm/yoheikikuta という podcast を始めて半年以上経ったので備忘録のために振り返りをしておく。反省会会場、と言いながらブログなので自分一人が振り返って書くだけなのだが、これはお察しの通りこのスレタイが好きだからつけただけである。hikifune.fm とは何だったのか？何だったのか？とか言うともう終わったものという感じもするが、まだ終わってはいない。コンセプトとか運用に関しては https://yoheikikuta.github.io/podcast_hikifunefm/ で書いた。機械学習に関連する事柄を配信することで自分たちの勉強に役立てようというものである（会社の仕事は諸般の事情により対外的に話しづらいということもあるので、勝手に勉強して勝手に話す場として準備している）。配信をしているので誰でも聞けるものではあるけど、聞き手にとってためになるとかではなくあくまで自分たちの役に立つという目的がメインで、一定間隔で配信をすることで配信ドリブンでインプットの意識を高めようという感じ。15 回配信をしてみての stats20210504 の時点で、総再生回数が 3,572 回で各エピソードの再生回数一覧は以下（正確には第 0 回もあったので 16 エピソードなのだが、第 0 回は単に始めます宣言なので一覧からは除いている）。一番再生されているのは Vision Transformer の論文解説で、一番再生されてないのは Prompt Tuning の論文解説（再生回数は時間に関して単調増加なので、最近の回が一番再生回数が少ないのはそれはそう）。内容的にある程度機械学習への理解がないと聞いても全く面白くないと思う Podcast なので、始める前は平均 100 回でも再生されれば結構凄いんじゃないかと考えていたので、思ったより再生回数は多いなと感じている。正直なところこの手の技術系 Podcast でどれくらい再生されるものなのか全く知見がないし調べてもいないので相場が分かってないが、hikifune.fm の場合はこんなもんだったということで。何か感想とか物申したいときのために Twitter hashtag #hikifunefm を準備したが、これは発表側以外では @karino2012 氏が感想を書いてくれたのみで他は殆どなかった。まあ自分も人の Podcast 聞いて感想を Twitter に書いたりしないので、そんなもんなんでしょうね。有名どころの Podcast だと感想を書いてる人もそこそこいる印象だけど、こっちはなんてたって曳舟だからね。ネームバリューがないよ（自分はもちろん曳舟好きだけどね）。show notes を GitHub repository https://github.com/yoheikikuta/hikifune.fm で管理していて誰でも issue に要望とか書けるようにしたけど、これは数としてはゼロ。Twitter hashtag 使われないくらいなんだから、そりゃ issue に何か書く人はいないでしょうな。この repository は issue を使うというよりは show notes をお手軽に管理したいという理由だったので、その目的は達した。良かった取り組み概ね隔週で配信してたけど、間隔としてはこれくらいがちょうどよかった感じがする。自分は発表者と聞き手を交互にやっていく役なので発表するのは 4 週に 1 回とかになる（実際はもうちょいハイペースだったが）ので、準備が怠くなってグダグダになりすぎるということはなかった。シリーズ物として DALL•E の理解に向けて というのをやったのは結構よかった。自分はあまりこういう方向性でやっていきたいというモチベーションがないので、単発で何かを話すだけだとあれこれ話題が飛ぶのであまり蓄積がなくて表面だけなぞって終わりがちだけど、3 回関連する話をすると自分の中でも理解が結構深まる。きっちりシリーズ物にしなくても、連続した数回はこういう系統の話でまとめる、とかやるとある程度はまとまった知識が得られるのでいいかもと思うなどする。show notes を割とちゃんと残した点もよかった。収録した音声はバグってないかは調べるけど最近はちゃんと聞き直したりはほぼしないので、この回はどんな話をしたっけというのを振り返りたい時に便利だったりした。そして収録前に repository に PR として送っておいて聞き手も見れるようにしておいたので、それを眺めながら聞くのはやりやすい（音声だけだとさっき何て言ってたっけ？とか忘れがちだけどテキストで書いてあるとすぐ確認できるので。Podcast 配信してるくせに身も蓋もない話だが、ちょっと込み入った話を音声だけで理解するというのは難しい）。イマイチだった取り組み二人で収録して聞き手を準備する、というのはそんなに効果がなかったなと思う。こういうのは大体準備ができるのが前日夜か当日収録前なので、聞き手は事前準備なく聞くことがほとんどで、質問がどうしても表面的で浅いものが多かった。まったく準備せずに聞き手として参加して素朴に質問することでリスナー目線で質問ができるかなという試みをしたりもしたが、そもそも自分たちの勉強のためにやってるものなのでやっぱりもうちょっと深い話に立ち入りたいよなというのが個人的な感想（それはそもそも Podcast で配信するような類のものではないのでは？という尤もらしい疑問は置いておいて）。その他にも細々した点はあるっちゃあるが、まあでも概ね良かったのではないか。ポジティブシンキングである。今後の方向性これを決めあぐねている。自分がやりたいと言って始めたもので他メンバーにちょっと負担を強いていた面もあったので、やっぱり発表者が自分以外には集まりづらい。他の人とワイワイやっていくスタイルにしたいなと最初は思ってたけど、自分一人でやっていくスタイルにするか。この場合は「あれ？なんで Podcast で配信してるんだっけ？ブログとか paper-reading とかでいいのでは？」となりそうな気配はする。発表内容を予め通達して、その内容に関して自分と同等以上に詳しい人を聞き手として招いて、自分の話に色々突っ込んだり補足を入れてもらうというのは自分の勉強にはよさそうだ。この場合は聞き手を探すのが大変という未来が容易に想像できるが。もともと自分たちの勉強になるというモチベーションで始めてある程度は役に立ったけど、そういうのはやっぱり少人数の勉強会で議論するのが一番いいんだよな（なかなか気軽にそれができる情勢になってはくれないのだが）。目的を変えて自分が興味ある話を紹介して自己満足する場にするか、ある程度やって満足したからもういいかとスパッと止めるか。どうするかまだ決めてないけど、ちょっと考えてみて近いうちに決めることにしよう。まとめhikifune.fm の反省会をした。今後どうしていくかはまだ未定。","link":"https://yoheikikuta.github.io/lookback_on_hikifunefm/","isoDate":"2021-05-02T00:00:00.000Z","dateMiliSeconds":1619913600000,"authorName":"yoheikikuta","authorId":"yoheikikuta"},{"title":"clasp と TypeScript で GAS の開発環境を整えた備忘録","contentSnippet":"TL;DRちょっとした仕事で GAS を使うときがあるローカルで clasp と TypeScript を使って開発する環境を整えた（が、いまの自分の用途ではここまでしなくてもよかった）完全に忘れそうなので備忘録としてブログに残しておく仕事で Google Workspace を使っていると、そのサービスを使ったちょっとしたタスクをするときに Google App Script (GAS) を使う時がある。スクリプトエディタで書いてたりもしたが、Git/GitHub での管理がしづらかったり、ローカルでの開発環境を提供する clasp https://github.com/google/clasp が TypeScript をサポートしているという話を知ったり（だいぶ遅い）して、せっかくなのでローカルでの開発環境を整えてみるかと思い立ってやってみた。一瞬で全て忘れそうなので備忘録としてブログに残しておく。諸々のインストール自分が使ってる Node と npm のバージョンは以下。$ node -vv15.9.0$ npm -v7.5.3npm で必要なパッケージをインストールする。TypeScript とか TSLint とかも入ってるけどそこはまあよしなに。$ npm install -g typescript tslint @google/clasp @types/google-apps-script自分が使っているのは以下のバージョンになっている。$ npm list -g/Users/yoheikikuta/.npm-global/lib├── @google/clasp@2.3.0├── @types/google-apps-script@1.0.25├── clasp@1.0.0├── tslint@6.1.3└── typescript@4.1.5...clasp login で Google OAuth 2.0 を使った認証が実施され、Authorization が成功すると ~/.clasprc.json というファイルにログイン情報が保存される。開発のためのセットアップ適当にディレクトリ（ここでは sample とする）を掘って npm init などをする（yarn がよかったらよしなに読み替える）。$ mkdir sample$ cd sample$ npm init -y$ tslint --initこのディレクトリで新しい script project を作成する。standalone の script project を作成する。https://github.com/google/clasp を見ればいいんだけど、ここでは script project のタイトルと root directory を設定している。後者を設定しておくとこの root directory に置いてあるものだけが push したときにスクリプトエディタに送られて便利なので設定しておくのがよい（これを設定しない場合は不必要なファイルを push しないように ./.claspignore を作る必要がある）。$ clasp create --title \"sample-title\" --rootDir ./src ? Create which script? standaloneGAS API を使ったことがなければ初回はエラーが出るので、https://script.google.com/home/usersettings で Google Apps Script API をオンにする必要がある。セットアップが整ったことを確認するために、簡単な GAS を作って push して実行してみる。./src/sample.ts を以下のように準備する。function test(): void {    console.log(\"hellow world.\");}このファイルを以下のコマンドで Google Drive に push する。./src/ 以下のファイルが push される。.ts ファイルが .gs ファイルにトランスパイルされて、GAS として実行できるようになる。$ clasp push└─ src/appsscript.json└─ src/sample.tspush されたファイルは GAS として Google Drive に保存される。GAS をスクリプトエディタ（script.google.com）で開くには以下を実行する。$ clasp openこれで以下の図のようにスクリプトエディタが開く。// Compiled using ts2gas 3.6.4 (TypeScript 4.1.5) とか書いてあってトランスパイルされたことも確認できる。型アノテーションも落ちている。実行 すればよいという寸法である。Google Drive に GAS として保存されたコードをローカルに持ってくるには clasp pull をすればよい。これをすると .gs ファイルから .js ファイルにトランスパイルされてローカルの ./src/ 以下に保存される。pull するとローカルに同じ内容の .ts ファイルと .js ファイルが存在するようになってしまうので、再び push すると 400 エラーで A file with this name already exists in the current project: sample となるので、push するには .js　ファイルを削除する必要がある。ローカルで開発する場合は pull は殆ど使わない、ということになりそう。./clasp.json に \"fileExtension\": \"ts\" を追加しておくと .ts ファイルとして pull してくれるが、当然型アノテーションとかは破棄されてるので嬉しいことは特にない。）これだけでもやりたいことはやれなくはないが、コードを動かすために push してから毎回ブラウザを開いて実行ボタンを押下しないといけないのでしんどい。App Script のランタイムは Google の基盤にあるので push して実行しないといけないのはいいのだが、せめてローカルでコマンドを叩いて実行してその結果をローカルで確認する、くらいはしたい。それをするためには色々と面倒な準備をしないといけないので、以降ではそのやり方を記録していく。ローカルで clasp run が実行できるようにするこれがダルい。かなりダルいのでもっといい感じにできるようになって欲しいが、とりあえず自分がやった手順を残しておく。何もしない状態で clasp run を実行するとどうなるかをまず見ておく。clasp run を実行するとどの関数を実行するか選択できるので、今回であれば test を選ぶ。$ clasp runRunning in dev mode.? Select a functionName testCould not read API credentials. Are you logged in locally?こんな感じで API credentials が読めないと怒られる。これを解決するために具体的な手順として以下を実施することになる。GCP プロジェクトと連携GAS を実行可能 API として公開App Script API を有効化認証情報の作成とそれを用いたログインGCP プロジェクトと連携するにはスクリプトエディタで プロジェクトの設定 を選択し、GCP の プロジェクトの変更 から連携させたい GCP プロジェクトのプロジェクト番号を設定すればよい。実行可能 API として公開するには、スクリプトエディタの デプロイ \u003e 新しいデプロイ において 実行可能API としてアクセスできるユーザをお望みのものに設定した上でデプロイする。この段階で clasp pull すると ./src/appsscript.json に executionAPI が追加されることが確認できる。{  \"timeZone\": \"America/New_York\",  \"dependencies\": {},  \"exceptionLogging\": \"STACKDRIVER\",  \"runtimeVersion\": \"V8\",  \"executionApi\": {    \"access\": \"MYSELF\"  }}GCP のプロジェクトで APIとサービス \u003e ライブラリ で Apps Script API を検索して有効にすることもやっておく（もし過去に有効にしたことがなければ）。最後に認証情報を作成してそれを使ってログインをする。APIとサービス \u003e 認証情報 の 認証情報を作成 で、OAuth クライアント ID を デスクトップアプリ アプリケーション用に作成する。この認証情報を json としてダウンロード（以降ではこのファイル名を creds.json とする）して適当な場所に置く（ここでは sample ディレクトリ直下に置いたものとする）。? What is your GCP projectId? と聞かれるので GCP のプロジェクト ID を入力する。$ clasp login --creds creds.json これが成功すると、sample ディレクトリ以下にこのプロジェクトで使用するアクセストークンなどが記載された .clasprc.json というファイルが作成される。ここまで来れば clasp run が実行できるようになるのでやってみる（以下のように実行したい関数名を指定して実行することができる）。$ clasp run testRunning in dev mode.No response.ということで、動く！clasp run では返り値が表示されることになるので console.log() とかの結果は表示されない（これに関しては次の節で書く）。適当な string とかを return すればちゃんと結果が表示されることが確認できる。ログの確認ログは GCP の Cloud Logging で管理されている。clasp のコマンドでローカルでも確認できるようになっている。$ clasp logsただし、これは連携している GCP プロジェクトに関するログがそのまま表示されてしまうので、そのプロジェクトが色々な用途で使われているものだとお望みの GAS のログを見つけるのが難しい。GCP のログエクスプローラだとフィルタリングのためのクエリが発行できるのでそれを clasp でも使えるとよいのだけど、20210223 時点ではサポートされていない。諦めてログエクスプローラで以下のようなクエリ（その他必要な条件は適宜つけて）を発行して見るしかないかな。resource.type=\"app_script_function\"resource.labels.invocation_type=\"apps script api\"GAS のサービスを使うここまで長々とやってきたが、GAS を使うなら GAS のサービスを使いたいわけで、それをするには使いたいサービスに応じて適切な permission を設定する必要がある。これは必要なものを ./src/appsscript.json に記載しましょうという話なのだが、せっかくなので一つ例を。先ほどまで使っていた ./src/test.ts を以下のように書き換える。function test(): string {    var response = UrlFetchApp.fetch('https://httpbin.org/get');    return response.getContentText();}これを実行しようとすると以下のようなエラーが出る。$ clasp push \u0026\u0026 clasp run testException: ScriptError Exception: You do not have permission to call UrlFetchApp.fetch. Required permissions: https://www.googleapis.com/auth/script.external_request [ { function: 'test', lineNumber: 3 } ]この permission を ./src/appsscript.json に加える。{  \"timeZone\": \"America/New_York\",  \"dependencies\": {},  \"exceptionLogging\": \"STACKDRIVER\",  \"runtimeVersion\": \"V8\",  \"executionApi\": {    \"access\": \"MYSELF\"  },  \"oauthScopes\": [    \"https://www.googleapis.com/auth/script.external_request\"  ]}これを追加したら改めてログインして再度実行する。 ? Manifest file has been updated. Do you want to push and overwrite? と聞かれるので y で答えると変更した appscript.json が push される。うまくいけば以下のようにちゃんと結果が帰ってくる。$ clasp login --creds...$ clasp push \u0026\u0026 clasp run test...Running in dev mode.{  \"args\": {},   \"headers\": {    \"Accept-Encoding\": \"gzip,deflate,br\",     \"Host\": \"httpbin.org\",     ...  },   ...  \"url\": \"https://httpbin.org/get\"}これくらいまでできるようになれば、何かしらのサービスの API を叩いてちょっとした処理をするのを GAS で定期実行するコードを書く、とかもローカルでできるようになってめでたしめでたし。その他clasp run foo で関数 foo を実行するときに引数を渡すこともできるが、これはシングルクォーテーションで囲んで例えば string なら clasp run foo --params '\"paramString\"' みたいに書く必要があるので注意。まあ README https://github.com/google/clasp/tree/ee70a6ae743d3b28b27b2c5cc6ca3e70c64f465b#options-11 とかコードをちゃんと読めってだけの話なんだけど。npm パッケージを使いたい場合はどうするんだっけというのもあるが、これはローカルでビルドして push せいという話みたいなので自分にも必要性が発生したら調べたらよさそう。それ以外にも設定ファイルの細々したこととかあるけど、大した話じゃないので割愛。テストとかデバッグとかGAS を使いたいときは GAS のサービスを使いたいときが多いので、やはりローカルだと限界があって、結局はスクリプトエディタでデバッガを使いながら期待通りの動きをしているのか確認する、というのが試行錯誤しながら開発するときは効率的ということになりそう。ある程度しっかり開発するなら、ローカルでモックを準備してテストもできるようにして、とか複数人で開発できるようにして、とかで今回のような環境をちゃんと作った上でやっていくのがよいと思うけど、自分の用途としてはそこまでガッツリしたものを GAS で作ることはなかなかなさそう。ということで、自分の用途に限れば、黙ってスクリプトエディタで開発して出来たコードは gist なりなんなりで共有しておけば十分、という感じかもしれない。「そしたらなんのためにローカルで TypeScript で書いたの」だって？せっかくだからちょっとやってみようと思ったからだよ、こまけぇこたぁいいんだよ。（AA略オチがついたところでこのエントリは終了。参考にした情報文中で書いたものもあるがまとめて羅列しておく。clasp: https://github.com/google/clasphttps://developers.googleblog.com/2015/12/advanced-development-process-with-apps.htmlhttps://developers.google.com/apps-script/referencehttps://developers.google.com/apps-script/manifesthttps://developers.google.com/apps-script/api/how-tos/executehttps://developers.google.com/apps-script/reference/url-fetch/url-fetch-appまとめclasp + TypeScript でローカルで GAS の開発ができる環境を整えたという話。","link":"https://yoheikikuta.github.io/GAS_local_development_env/","isoDate":"2021-02-22T00:00:00.000Z","dateMiliSeconds":1613952000000,"authorName":"yoheikikuta","authorId":"yoheikikuta"},{"title":"2020年のまとめ","contentSnippet":"TL;DR2020 年も頑張った（4 年連続 4 回目）。4 月に社会復帰して途中で折れずに働き続けた超人として自分を褒め称える2021 年も頑張っていきますか〜！！！2020年が終わった。 全体的によく頑張った。毎年頑張っていて偉い。本当に偉い。凄い（去年のをコピペ）（去年のをコピペ）（去年のをコピペ）。このブログを始めて 4 回目の一年振り返りエントリで、これくらいの数になってくるとやっとるな感が出てくるね。無職をやめて社会復帰（就職）した甘美な無職期間に終わりを告げ、社会復帰を果たした。無職期間は 20190201 ~ 20200331 だった。最後の方は結婚式費用のために現金を稼がねばならずフリーランス業をいくらかやったが、結婚式は延期になったのでノーカンで（謎理論）。無職期間に何をしていたかは去年の年末ブログエントリ https://yoheikikuta.github.io/Summary2019/ に色々書いたのでそちらに譲るとして、無職最高なのでみんなやった方がいいぞということだけここで改めて言っておきたい。沖縄に行って海辺をランニングして仕事に関係ない数学書とか哲学書を読んだり、海外に遊びに行って知り合いの家に居候したり、なにも考えずにただひたすら漫画を読んだり、やりたいことを元気があるうちにやっとくのはいいな〜ということを満喫できる。また、仕事についてちゃんと考え直す機会としても良かった。仕事をしているときは「自分がやっている仕事は面白いし意義がある」と思い込む傾向がある。これは必ずしも悪いことではないけど、意識的に思考を切り替えないと自分が普段やっている仕事の枠内でしか物を考えなくなりがちなので、思考の切り替えのためにも無職期間は適している。ということで次に何をするかについては色々と考えて、多くの会社の話を聞いたり実際に受けたりして就職先を検討した。人に語れるようなストーリー（真に価値があると信じることができて、アルゴリズムやデータが本質的に重要で、得られる知見に普遍性があり、インパクトも大きい）があって、経済的にも成功できる（所得税は高すぎるので SO も有力な選択肢）、という観点を大事にした。最終的に Ubie 株式会社という会社に入社した。その時の経緯はブログエントリ https://yoheikikuta.github.io/joinning_ubie/ にも書いたので、詳しくはこちらで。Ubie での仕事「人に語れるように、とかなんとか言っておいて君は仕事のこと全然語ってなくない？」自分のことを客観的に見たらこういう疑問を抱く。やめてくれカカシ、その術はオレに(ry…どういう感じで働いてるのか、についてはまた別のブログエントリで（できれば）詳しく書きたいと思っているが、業種的に内部での取り組みを大っぴらに話しづらいという傾向がある。法的に未整備な領域も多いので慎重に進める必要があるし、データは知見の山だが内容を公開となるとやはり慎重を期す必要がある（どうしてもデータにはエラーやノイズが含まれるし、万一それによって不利益を被る人がいたときに深刻な問題となり得る）。この辺りは入社してからそういえばそうだな〜と気付かされた部分で、不満を感じている部分ではある。組織の取り組みとかは公開してるしそれはそれで面白いし大事だけど、自分がアウトプットするならもっと普段の業務内容に近い技術的な内容がいいなと思っているので、これまで会社での仕事のことはほとんどアウトプットできていなかった。やりたいけどなかなか変えづらい部分でもあるので、外向けに色々話すための個人的なアウトプットの場として Podcast を始めたりした（後述）。それ以外に関してはかなり満足して働けている。「”あの” 菊田さんが活き活き働いている」ということで Ubie に転職決めてくれた人も何名かいらっしゃいます。基本的にどの会社で働いている時も活き活き働いていたはずなのですが、ともかく話を聞いてみたいという人がいればお気軽に連絡ください！個人的に話す分には語りまくれるので語りまくります。業務内容をめちゃくちゃ雑に書くと、データサイエンスチームでデータ周りの諸々やアルゴリズムの改善などを主たる業務にしている。今年は特に「いかにして質の高いデータを集めてそれを使ってサービスを改善するか」という部分に注力していて、技術的に面白味がない部分も大量にあるけどデータが面白いのでめちゃくちゃ頑張った。かなり良い感じになってきたので、来年はアルゴリズムの改善でいろいろなアイデアを試せそうで楽しみ。何はともあれ 20200401 に入社して以来ここまで働いてこれたので、ただただ自分を褒めるのみである。超人だよ自分は（そして同様に働いている他の人々も）。インプット/アウトプットのために hikifune.fm という Podcast を始めた始まりました。前述の通り、技術的な内容をアウトプットする場がないので、新しい取り組みとして Podcast を始めた。そのことを書いたブログエントリはこちら https://yoheikikuta.github.io/podcast_hikifunefm/コンセプトは自分たちの勉強のため、というものなので、基本的にゲストを呼んで話してもらうとかはしないし内容も自分たちの興味があるものだけを対象にしている。隔週で配信しているが、これくらいが負担が少なくてよさそうな感じがしている。再生回数がどれくらいかというと以下の通り。最近リスナーが減っている感じもあるが、まあこんなもんかという感じ。内容が内容だし、時間も長めなので、平均して 100 人以上も聴いている人がいるというのは十二分な感じがしている。Podcast の取り組みについては概ね満足しているけど、ちょっとトピックがつまみ食い的な感じもあるので、自分が発表する番に関してはもう少しテーマを持って何回か連続してやってもいいかな〜などと考えている。Work From Home (WFH)今年は WFH が自分の中でスタンダードになったというのは大きな出来事だった。これまで働くんだったらやっぱり環境が整っているオフィスに行って議論とかできた方がいいよな、と思っていたけど、そうも言ってられない状況になったので WFH で満足いく働き方を実現しようと思って色々と頑張った。最終的に在宅勤務環境がこんな感じになったというブログエントリはこちら https://yoheikikuta.github.io/work_from_home_environment/正直引越し前はコワーキングスペースを借りたりなんだりしてたけど、かなり生産性が低かった。転職したてで色々慣れていなかったということもあったけど、あの頃はあまり価値を発揮できていなかったのでよくなかったなと反省。真面目に WFH 環境を整えてからは驚くほど生産性が上がった。ホワイトボードを使って人と議論する時以外は全部 WFH でいいじゃん、と思っている。WFH 最高だし、物理出社しないと原理的に業務ができない人たちのため（感染リスクを下げる）にも、WFH で働ける人はみんなそうすべきだよねと思う程度には推進派になった。WFH で肩凝りに悩まされることがなくなったというのも良かった点。スタンディングデスクやらの設備投資と、家だと好きなだけ動き回れるという利点も相まって、肩凝りはかなり軽減した。ゲームやるときにずっと座ってやってて肩凝るので、一番の難敵はゲームだと理解した。反省点は圧倒的運動不足。これは来年の目標に明示的に入れてやっていこう。運動不足とは直接関係ないが、今年はピロリ菌感染疑いで胃痛が発生したりして健康を意識した一年でもあった。除菌をしてある程度収まったのでいまは大丈夫だが、やはり健康第一なので運動含めてちゃんと体調管理していこうと思った次第。その他毎年元旦にその年の目標を書いて（プライベートな内容も多いので公開してない）ちょこちょこチェックしてるけど、一年経って見返してみるとアウトプットの量と運動の項目に関しては未達が多かった。アウトプット量に関しては、会社でかなりの量のテキストを書いてるのでそれで満足しちゃっているという面があるので、大きく変えるというのはなかなか難しいかもしれない。運動に関しては一番の課題に感じてるので、これは意識して改善しよう。体重とかはほとんど変化してないけど、あからさまに体力が落ちてる気がする（気がする、は運動をしてなさすぎてそれを自覚するイベントがない）。PS5 を買えたのは良かった。グラフィックが素晴らしくてデモンズソウルを一からのやり直し含めて 5 周以上プレーした。来年以降色々とソフトも出るだろうし、楽しみ。Web 上での存在感は薄くなっているので、そこはもう少し頑張っていきたいかな。Twitter とか全然できてないし。Trickle の year stats は 912 activities, 279 days だったので、Twitter も同じくらいは頑張りたいところ。ということで、来年も頑張っていきましょう。まとめ2020 年も終わりです。みなさま良いお年を。","link":"https://yoheikikuta.github.io/Summary2020/","isoDate":"2020-12-30T00:00:00.000Z","dateMiliSeconds":1609286400000,"authorName":"yoheikikuta","authorId":"yoheikikuta"},{"title":"2020年に読んだ本を一言コメントと共に振り返る","contentSnippet":"TL;DR2020 年に読んだ本を可能な限り思い出して振り返ってみる詳しい書評を書くのはキツいので一言コメントを添えて仕事を始めるということで組織系の本が多め。技術書は少ないな〜2020 年に読んだ本を思い出せる分だけ一言コメントと共に振り返ってみる（記録を残してない書籍もあるが、それらは無視）。雑に技術書と読み物に分けて、雑多に書いていく。一言コメント、と言いながら結構な量のコメントな気もするが、気にせずいこう。技術書Google BigQuery The Definitive Guide amazon へのリンク入門ベイズ統計 意思決定の理論と発展 amazon へのリンク科学と証拠 ―統計の哲学 入門― amazon へのリンクベイズ推論による機械学習入門 amazon へのリンクPython の黒魔術 BOOTH へのリンク__get__(), __set__(), __delete__() のどれかを持ってるオブジェクト。 instance メソッドや class メソッドや static メソッドで何が行われているのかが理解できる。第11章の例外とトレースバック。sys.excepthook という例外ハンドラを自分で置き換えてトレースバックを変更したり表示カラー化をしてみるという章。トレースバックこうなってたのねというのが理解できるのがよかった。Visual Studio Code Ninja Guide BOOTH へのリンクGitHub Actions 実践入門 amazon へのリンクレガシーコードからの脱却 amazon へのリンクRust プログラミング入門 amazon へのリンクデータ指向アプリケーションデザイン amazon へのリンク読み物闘うプログラマー amazon へのリンク文芸的プログラミング amazon へのリンク独創はひらめかない amazon へのリンクThe Elements of Style (Fourth Edition) amazon へのリンクhttps://twitter.com/polm23/status/1343874246557110273 をいただいて気付けました）。この本に誤りが多いことは https://www.chronicle.com/article/50-years-of-stupid-grammar-advice などにも書いてあります。みずほ銀行システム統合、苦闘の 19 年史 amazon へのリンクMeasure What Matters amazon へのリンクLearn or Die 死ぬ気で学べ プリファードネットワークスの挑戦 amazon へのリンクHOW GOOGLE WORKS amazon へのリンク\b1兆ドルコーチ amazon へのリンクティール組織 amazon へのリンク1984年 amazon へのリンクホラクラシーの光と影 amazon へのリンクHolacracy: The New Management System for a Rapidly Changing World amazon へのリンクNO RULES amazon へのリンクまとめ仕事を始めて会社で色々と新しい組織的な取り組みをしているので、組織系の書籍を読むことがまあまあ多かった。","link":"https://yoheikikuta.github.io/book_I_read_in_2020/","isoDate":"2020-12-29T00:00:00.000Z","dateMiliSeconds":1609200000000,"authorName":"yoheikikuta","authorId":"yoheikikuta"},{"title":"在宅作業環境","contentSnippet":"TL;DR在宅勤務が中心になったので、在宅作業環境を整えたQOL を高めるのはやはり昇降式デスクとホワイトボード在宅勤務が中心になり、在宅で作業する時間が日々の生活において支配的となった。在宅勤務は最高なので、仮に COVID-19 が過ぎ去ったとしても在宅勤務中心にしたい。より快適な時間になるように在宅作業環境を整えたので、どんな環境かをまとめておく（ひまこつ先生の記事 https://note.com/himkt/n/n80b95e5933a6 を読んで自分もまとめてみるか〜となったので）。無課金ユーザー時無職を辞めて働き始めたときは物理出社をする気満々だったのだが、在宅勤務となってしまい以下のような環境だった。これが在宅勤務環境のリアル。やはり段ボールが最強だったか。 pic.twitter.com/i7OGV7IvNE— Yohei KIKUTA (@yohei_kikuta) April 8, 2020 これで十分にパフォーマンスが出せればそれで良かったのだけど、（あまり言いたくないが）ある程度の年齢になってくると身体がついてこれなくなりがちである。自分の場合は肩こりが酷いので、肩こりが生じないような環境を構築するのは必須であった。在宅作業環境構築現在の在宅作業環境をトピック別にまとめておく。引越色々ちょうどよいタイミングだったこともあり、まず引越しをした。一人暮らしの場合は気にしなくていいけど、同居人がいる場合はやっぱり独立した作業部屋があった方がいい。在宅勤務だと仕事する人も仕事しないけど同じ空間にいる人も気を遣って精神的に健康で無くなる場合があるので、独立した作業部屋があるのは在宅勤務を成立させる重要な要素であると思う。都心だと家賃が高いので、ちょっと離れて家賃を抑えつつ、必要があれば都心へのアクセスも容易というところが快適だなと感じている。自分としてはおすすめの場所があるんだが、他に推している人を見たことがない。東京を離れるという選択肢もアリだと思うけど、東京は色々便利なんだよなぁ…デスク周りまずは写真をガッと。PC は会社支給の MacBook Pro (13-inch, 2019, Four Thunderbolt 3 ports) でメモリが 16[GB] のもの。ここが失敗したポイントで、持ち運びを考えて絶対 13-inch だと思ってこれにしてもらったが、在宅勤務中心にするなら 16-inch でメモリもデカいのにすればよかった（自分が買った時は 13-inch の 32[GB] は出てなかった）。自分は大して重い処理をさせないのでまあ問題はないのだけど、M1 チップも出てるしそのうち新調するかねぇ。ちなみに個人用のマシンは MacBook (Retina, 12-inch, 2017) でメモリが 16[GB] のもの。無職時代は小ささと軽さ重視だったのでこれを使ってて、いまはプライベートで諸々やる場合にちょこちょこ使っているという感じ。iPad Pro (11-inch, 1st generation) は論文と漫画を読む用に使っている。以前は計算するときとか絵を描きながら考え事をするときにも使っていたけど、いまはホワイトボードがあるのでそういう用途ではあまり使わなくなった。モニターは DELL 27-inch U2720Q で、アームは ergotron LX デスクマウントアーム で、会社支給。モニターを使わない生活に慣れてたけど、一回使い始めるとやっぱりあるといいよねってなる。キーボードは Mistel BARROCO MD770 で、周辺機器として Magic Trackpad 2 とか PC スタンドとかと合わせて会社支給。キーボードはメカニカルへのこだわりとかは全然ないのだが、肩こり防止のために分離式がよくて、できるだけデフォルトに近い設定で使えるということでこれを選んだ。どうしてもキーマッピングはちょっと設定しないといけない、キー数を減らしてくれた方が嬉しい、付属品のケーブルは短いので別途用意しないといけない、というのはあるけど概ね満足している。デスクは パブロ2 電動昇降デスク 幅1200×奥行700 にした。FlexiSpot 買ってる人が多い印象だったけど、これが目に止まって良さそうだったのでこれを買ってみた。比べてないからどっちが良いとかは分からんけど、買ったものに関しては圧倒的に満足している。昇降式デスクこそが自分が欲していたものだな、というレベルで昇降式デスクが好きになった。やっぱり座りっぱなしで作業するより頻繁に立ったり座ったりを繰り返す方が身体を動かして肩こりにも効く。MTG 中にもよく立っているので、会社では座ってじっとしていられない人として認識されている。椅子は Steelcase Gesture にしてみた。あんまり買ってる人いなそうなのでいっちょ試してみるか〜という感じで買ってみたが、リクライニングの気持ち良さがたまらない。あとアームの自由度が高いのも使いやすくていい感じ。イヤフォンは SONY WI-1000XM2 を使っている。家の中でも外でも使いたいのでワイヤレスは必須で、デカいのは嫌いなのでヘッドフォンは除外で、一日の使用であれば充電要らずで持つ、ということでこれがいいのではないかと思っている。在宅勤務だと打ち合わせは全部オンラインだしそれ以外にも Discord で話したりもするので、充電なしで一日使えるというのは結構重要と思う。使わない時はイヤフォンを耳から外せばそのまま首にかけて保持できてほとんど気にならないので、これが攻守最強か？と感じている。ホワイトボードは イワキボード の 幅1200×高さ900 が愛用の品。以前使ってたものは無職になるときに前職職場に寄付したが、作業環境整えると言ってるのにホワイトボードないとかお話にならないよねと思い再度購入。残りの人生でも何回も買いそう。ホワイトボード使い始めるとホワイトボードがなかったころの生活が思い出せなくなるほど有用なので圧倒的にオススメ。その他在宅勤務を快適にするために準備してよかったなと思うものたち。まずはドクターペッパー。やっぱりね、仕事中に飲むドクぺは最高なんですよ。オフィスの良さの一つには飲み物とかが充実しているという点も挙げられると思うけど、ドクぺが常備してあれば在宅勤務が優勝です。コーヒーを自分で淹れるための諸々。自分はそんなに味にこだわりがないのでインスタントとかでも十分なんだけど、自分でのんびりコーヒー豆挽いてコーヒー淹れたりするのは良い気分転換になるので、いったん脳を落ち着けるのにコーヒーを自分で淹れるというのはなかなか気に入っている。トリガーポイントボールとストレッチ用のゴムチューブ。肩こり撲滅用。トリガーポイントボールは知人に勧められて買って良かったものの中でもかなり上位に入る。初代は破損してしまったので、二個目を購入した。あと在宅勤務ってのとはちょっと違うけど、バルミューダのトースター買ってパン焼いて食べたら最高だったので、これも良かった。不満足な点ほとんどの点で満足しているのだけど、全然散歩にくり出せてない点はいただけない。在宅勤務の良さの一つは起きてそのまま仕事ができることなのだが、外に出るためには着替えて玄関まで行って靴を履かなければならない。これは恐ろしいほどハードルが高く、現時点では全くと言っていいほどできていない。歩きながら考え事をするのはとても良いのでなんとか取り入れていきたいが、今のところ良いソリューションは思いついていない…まとめ在宅作業環境についてまとめてみた。昇降式デスクとホワイトボードが二大重要アイテム。","link":"https://yoheikikuta.github.io/work_from_home_environment/","isoDate":"2020-11-27T00:00:00.000Z","dateMiliSeconds":1606435200000,"authorName":"yoheikikuta","authorId":"yoheikikuta"},{"title":"Jasper による（データ分析系）タスクの作業ログ管理","contentSnippet":"TL;DRリモートワークでより一層作業ログを残すのは重要になったが、Jasper での管理がめちゃくちゃ捗る分析系のタスクは SQL クエリだけだと情報が不十分なことが多く、作業ログに過程を残しておくと便利チームで同じように作業ログを残しておくと作業追いやすいしコメントとかも随時入れられるのでよいリモートワークがメインになって久しいが、リモートワークはスッとお布団で昼寝とかできたりして最高なので、今後もこれが自分の標準的な働き方になる（少なくとも必要な時はいつでもリモートで働けるようにする）という感じがする。リモートワークがメインになって色々と変わったけど、その中でもこのエントリでは作業ログを残すことについて、いま自分（もしくはチーム）がどういう感じでやっているかを残しておこうと思う。リモートワークになって作業ログを残す重要性はより一層高まった。社内 wiki に日報を書くとか Slack に分報を書くとか色々あると思うが、自分の場合はタスク毎に GitHub の Issue に作業ログを残してそれを Jasper で管理するのがしっくりきている。特にチケット管理をしている分析系のショットのタスクとかも相性がいいので、その辺りを中心にまとめる。Jasper https://jasperapp.io/ って何？という人がいたら、最高 GitHub Issue reader なので使ってみてください。ドキュメントはこちら https://docs.jasperapp.io/ （自分は Jasper の回し者ですが、完全ボランティアの回し者です）。具体的にどんな感じか？百聞は一見に如かず、ということでどんな感じなのかキャプチャ画像をば（ほとんどモザイクかかってるけど）。sandbox_yoheikikuta というリポジトリの Issue で管理していて、大まかに Data Science (DS) 系とか採用系とかで Label を付与している。この Issue にはタスクを完遂するまでにやったこととか考えたことを割と細かく残すようにしている。分析系タスクだとコードだけだと情報が不足していることも多いので、後でまた似たようなタスクをやろうとしたとき（これは未来の自分だったり同僚だったりする）に追えるようにしたいという考えからこうしている。分析系タスクで情報が不足しがちというのはどういうことかというのは後で別セクションで書く。ともかく、こんな感じで自分やチームの人が Issue に作業ログを残してくれていれば、Jasper を使うことで作業ログを追ったり探したりしやすいのでめちゃくちゃ管理しやすい。自分は以下のように使ってる。チームの一部の人は同様の運用をしてるので、notification なしで Jasper の Stream を作成して、自分の手が空いたときとかに眺めて他人の作業を理解したりコメントしたりしているこれは過去に同じようなことしてたな〜ってなれば Cmd+K で jump したり JIRA のチケットから探したりして必要な情報を収集する（もちろん典型的な使い方として PR のレビューとかにも使ってるが、そういう典型的な使い方はこのエントリでは詳しくは触れない）Issue に作業ログを残すだけでは閲覧性が悪かったりして有効に活用するのが難しい。Jasper という Issue reader が存在してくれることによってうまく機能する仕組みになっている。ありがとう Jasper さん。リモートワークにおける作業ログの重要性作業ログを残していざとなったら他の人に引き継いでもらっていつでも退職できるよう（？）にしておくことはそもそも重要なんだけど、リモートになってより一層作業ログを残しておくのは重要になった。物理出社してた時は、ふらっと集まって議論して sync したり、集中力がなくなったときに他人の作業を覗きに行って何してるか聞いてみたり、とかができるけどリモートワークではそれができない。最初はツールでなんとかそれをできるようにしよう、ということで色々試してみたりもした。自分の中での結論は、ツールを活用して物理出社してたときと同じように働くというのは無理だな、というものだった。ある程度しっかりした議論が必要な時は時間を合わせてオンラインでやるとか、出社したときに存分にホワイトボード使ってやるとかで機会を確保していかないといけない。物理出社してた時と比べて入ってくる情報量が少なくなるので、その分はやはり作業ログとして残して共有していくしかない。日報だったり分報だったり色々あると思うけど、自分はやっぱり GitHub Issue が一番使いやすい。スクラム開発でチケット単位でタスクを管理していることとの親和性も高く、タスク単位で Issue にログを残していくのはうまく機能している。慣れてくると作業ログで非同期に共有できるのは時間を無駄にしなくて済む。格好いい感じで書いたが、チーム全体で見るとまだまだできてない部分もあるので、もっといい感じに機能するようにはしていきたいね。分析系タスクの作業ログ分析系タスクといっても色々ある。SQL だけで閉じずに Python のコーディングもしてガッツリ分析が必要なものに関しては、Jupyter Notebook で分析をしたものをリポジトリに push しておけばいいと思う。そこまで重くはないけど結果を得るまでには結構色々な知識が必要となるタスク、がちと厄介となる。よく管理されたコードベースであればコードを読めば理解できることが多いのでいいのだが、分析系のショットのタスクは当然そうではないし、そもそも SQL クエリは読むのはしんどい…例えば、過去一週間のアプリケーションログがなんかおかしそうだからその原因を調べたいとする。Issue の作業ログにちょっとしたコメントと共にこれらの情報を残しておけば、未来の自分へも同僚へも有益な情報となる。前回と同じような異常なら前回と同じ流れで確認すればいいし、違った種類のものであれば調べた経緯を同じように残して知見としていく。そしてそれらの知見には Jasper によって容易にアクセスできるといった次第である。これはいまのところうまく機能していて、自分は気に入ってるし、同様の管理方法を採用しているチームメンバーの評判も結構良い。いま考えている課題は、こういう知見をいい感じにまとめられるならまとめたいけどどうやればいいの？ということだ。まとめ（分析系タスクの）作業ログを GitHub Issue に残して Jasper で管理していて最高便利。","link":"https://yoheikikuta.github.io/working_log_using_jasper/","isoDate":"2020-10-30T00:00:00.000Z","dateMiliSeconds":1604016000000,"authorName":"yoheikikuta","authorId":"yoheikikuta"}]},"__N_SSG":true},"page":"/members/[id]","query":{"id":"yoheikikuta"},"buildId":"gWMH57DBziGrEAfcgWLuo","nextExport":false,"isFallback":false,"gsp":true,"head":[["meta",{"name":"viewport","content":"width=device-width"}],["meta",{"charSet":"utf-8"}],["link",{"rel":"icon shortcut","type":"image/png","href":"https://blog.ubie.tech/logo.png"}],["link",{"rel":"stylesheet","href":"https://fonts.googleapis.com/css2?family=Inter:wght@400;700\u0026display=swap"}],["title",{"children":"yoheikikuta | Ubie Engineers' Blogs"}],["meta",{"property":"og:title","content":"yoheikikuta"}],["meta",{"property":"og:url","content":"https://blog.ubie.tech/members/yoheikikuta"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"property":"og:site","content":"Ubie Engineers' Blogs"}],["meta",{"property":"og:image","content":"https://blog.ubie.tech/og.png"}],["link",{"rel":"canonical","href":"https://blog.ubie.tech/members/yoheikikuta"}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-fa276ba060a4a8ac7eef.js"></script><script src="/_next/static/chunks/main-8a83f0fd99327c4684a8.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/framework.1daf1ec1ecf144ee9147.js" async=""></script><script src="/_next/static/chunks/commons.8d61253ae98ee51657b8.js" async=""></script><script src="/_next/static/chunks/pages/_app-49079e3278dd6cef7229.js" async=""></script><script src="/_next/static/chunks/81b50c7ab23905e464b4340eb234bd6ea389d26b.5863e0c3fa35c0c78394.js" async=""></script><script src="/_next/static/chunks/pages/members/%5Bid%5D-f279413a3daf3c18264d.js" async=""></script><script src="/_next/static/gWMH57DBziGrEAfcgWLuo/_buildManifest.js" async=""></script><script src="/_next/static/gWMH57DBziGrEAfcgWLuo/_ssgManifest.js" async=""></script></body></html>