<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon shortcut" type="image/png" href="https://blog.ubie.tech/logo.png"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&amp;display=swap"/><title>smochi | Ubie Engineers&#x27; Blogs</title><meta property="og:title" content="smochi"/><meta property="og:url" content="https://blog.ubie.tech/members/smochi"/><meta name="twitter:card" content="summary_large_image"/><meta property="og:site" content="Ubie Engineers&#x27; Blogs"/><meta property="og:image" content="https://blog.ubie.tech/og.png"/><link rel="canonical" href="https://blog.ubie.tech/members/smochi"/><link rel="preload" href="/_next/static/css/5b1e5c056c67d836f701.css" as="style"/><link rel="stylesheet" href="/_next/static/css/5b1e5c056c67d836f701.css" data-n-g=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-8a83f0fd99327c4684a8.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.1daf1ec1ecf144ee9147.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.8d61253ae98ee51657b8.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-49079e3278dd6cef7229.js" as="script"/><link rel="preload" href="/_next/static/chunks/81b50c7ab23905e464b4340eb234bd6ea389d26b.83ad1c2705ae70f873e8.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/members/%5Bid%5D-f279413a3daf3c18264d.js" as="script"/></head><body><div id="__next"><header class="site-header"><div class="content-wrapper"><div class="site-header__inner"><a class="site-header__logo-link" href="/"><img src="/logo.png" alt="Ubie Engineers&#x27; Blogs" class="site-header__logo-img"/><span class="site-header__logo-text">Ubie<br/>Engineers&#x27; Blogs</span></a><div class="site-header__links"><a href="https://ubie.life/" class="site-header__link" target="_blank">Company</a><a href="https://recruit.ubie.life/jd_dev" class="site-header__link" target="_blank">Recruit</a></div></div></div></header><section class="member"><div class="content-wrapper"><header class="member-header"><div class="member-header__avatar"><img src="/avatars/smochi.jpeg" alt="smochi" width="100" height="100" class="member-header__avatar-img"/></div><h1 class="member-header__nickname">smochi</h1><p class="member-header__real-name">Shunichi Mochizuki</p><p class="member-header__bio">新規事業のグロースなど、いろいろやってます。スタートアップや機械学習に興味があります</p><div class="member-header__links"><a href="https://twitter.com/smochi_pub" class="member-header__link"><img src="/icons/twitter.svg" alt="Twitterのユーザー@smochi_pub" width="22" height="22"/></a></div></header><div class="member-posts-container"><div class="post-list"><article class="post-link"><a class="post-link__author" href="/members/smochi/"><img src="/avatars/smochi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">smochi</div><time dateTime="2021-06-02T07:17:34.000Z" class="post-link__date">7 months ago</time></div></a><a href="https://note.com/smochi_pub/n/n428024c8d9b4" class="post-link__main-link"><h2 class="post-link__title">高速な開発とデータ品質のトレードオフを超えるためにできること</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=note.com" width="14" height="14" class="post-link__site-favicon"/>note.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/smochi/"><img src="/avatars/smochi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">smochi</div><time dateTime="2020-12-13T15:39:10.000Z" class="post-link__date">a year ago</time></div></a><a href="https://note.com/smochi_pub/n/na1d2cde44b46" class="post-link__main-link"><h2 class="post-link__title">スタートアップにおける資産としてのカルチャー形成のすすめ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=note.com" width="14" height="14" class="post-link__site-favicon"/>note.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/smochi/"><img src="/avatars/smochi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">smochi</div><time dateTime="2020-10-25T16:09:35.000Z" class="post-link__date">a year ago</time></div></a><a href="https://qiita.com/smochi/items/c4cecc48e4aba0071ead" class="post-link__main-link"><h2 class="post-link__title">推薦システムのベンチマークに関する論文(Recsys2020)を読んだメモ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=qiita.com" width="14" height="14" class="post-link__site-favicon"/>qiita.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/smochi/"><img src="/avatars/smochi.jpeg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">smochi</div><time dateTime="2019-09-16T16:13:59.000Z" class="post-link__date">2 years ago</time></div></a><a href="https://qiita.com/smochi/items/98dbd9429c15898c5dc7" class="post-link__main-link"><h2 class="post-link__title">RecSys 2019 ベストペーパーを読んだメモ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=qiita.com" width="14" height="14" class="post-link__site-favicon"/>qiita.com</div></a></article></div></div></div></section><footer class="site-footer"><div class="content-wrapper"><p>© <!-- -->Ubie Discovery</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"member":{"id":"smochi","nickname":"smochi","realName":"Shunichi Mochizuki","bio":"新規事業のグロースなど、いろいろやってます。スタートアップや機械学習に興味があります","avatarSrc":"/avatars/smochi.jpeg","sources":["https://qiita.com/smochi/feed","https://note.com/smochi_pub/rss"],"twitterUsername":"smochi_pub"},"postItems":[{"title":"高速な開発とデータ品質のトレードオフを超えるためにできること","contentSnippet":"このnoteでは、事業立ち上げ期の高速な開発とデータ品質の間に発生するトレードオフに、限られたリソースで対処するために取り組んだ内容について紹介します。はじめまして。Ubie Discoveryで機械学習エンジニアをやっている望月(@smochi_pub)です。Ubieに一人目のデータ人材として入社して、BI的なデータ整備・活用から予測アルゴリズムの開発まで幅広く担当してきました。続きをみる","link":"https://note.com/smochi_pub/n/n428024c8d9b4","isoDate":"2021-06-02T07:17:34.000Z","dateMiliSeconds":1622618254000,"authorName":"smochi","authorId":"smochi"},{"title":"スタートアップにおける資産としてのカルチャー形成のすすめ","contentSnippet":"Ubie Advent Calendar 2020 の12日目の投稿です。Ubieではデータサイエンスチームに所属して、機械学習エンジニアをやっている望月 (@smochi_pub) です。創業初期に入社し、スタートアップのカルチャーが事業にあわせて変化、進化していく様を目の当たりにしてきました。その効用の大きさを当事者として強く感じてきたため、主にカルチャーに関する施策を行うチームにも所属してます。今回は後者のチームで携わったカルチャーガイドブックの作成と、その過程で考えたことについてご紹介していきます。続きをみる","link":"https://note.com/smochi_pub/n/na1d2cde44b46","isoDate":"2020-12-13T15:39:10.000Z","dateMiliSeconds":1607873950000,"authorName":"smochi","authorId":"smochi"},{"title":"推薦システムのベンチマークに関する論文(Recsys2020)を読んだメモ","contentSnippet":"紹介論文Are We Evaluating Rigorously? Benchmarking Recommendation for Reproducible Evaluation and Fair Comparison概要Recsys2020で発表された、推薦システムの公平なベンチマークに向けた調査と提案に関する論文論文の貢献主要学会を中心に推薦システム論文85本を系統的にレビュー, 性能比較において重要な要素を特定した実際に各要素ごとに対照実験を行い、再現可能性の高い性能比較データを提供した後続の研究者に向けて、比較実験が容易かつ拡張性も高いツール (https://github.com/AmazingDD/daisyRec) を提供したなぜ読もうと思ったか？昨年のベストペーパー (https://arxiv.org/abs/1907.06902) など、推薦システムに関する公平な評価に関心が集まっているので実務において、様々なモデルや処理が実際にどんなデータに有効なのか知っておくのは重要だと思ったから論文の背景近年、推薦システムの評価のための有効なベンチマークが存在しないことが問題になっている過去5年の多くの論文での手法比較が適切でないことを示した論文 (https://arxiv.org/abs/1905.01395) もある適切なチューニングを行うと新規手法は負けてしまう問題近年の深層学習を使った推薦の論文でとくに不可解な比較が多い指摘もあったCV系にはImageNetのような成熟したベンチマークがあるなぜ推薦システムでは難しいのか？同じ応用ドメインでも複数のプラットフォームの、種類の異なるデータが存在するため映画：MovieLens, Netflix, …データ量: 100K, 1M, …研究者が意図的にデータセットを選んで比較することが可能になってしまうデータの前処理、分割法、評価指標、パラメタ設定方法に多種多様な選択が存在する最低評価数, 分割比率などこれらの設定が公開されてないものが多いため、後続の再現を不可能にしている論文収集と分析論文収集8つの学会の過去三年分の論文リストから特定のキーワードが含まれている論文を対象とした\"recommend\", \"collaborative filtering\", …最終的に85本が対象となった（詳細は https://github.com/AmazingDD/daisyRec/blob/dev/Additional%20Material.pdf のTable5)意外と少ない印象学会、データセット、比較手法、評価関数などの分布を可視化した本研究で採用した、データセット、指標、比較手法は赤字になっているFig1主要な実験設定と問題点の分析データセット収集された論文からは二つの大きな問題が発見された同一ドメイン(映画、音楽、EC…）内に複数の代表的なデータセットがあるバージョンの多様性がある同じ名前のデータセットでもいくつかのバージョンが存在していたYelpは同一名義で３つのバージョンが存在したfig1(b)は上位15件のデータセット人気度を、論文が占める割合で示した85論文中90%の論文が上位15データセットの少なくとも1つを採用している本研究ではデータセットの人気度とドメインカバレッジを考慮して、6つのデータセットを採用したML1M(映画), Lastfm(音楽), Yelp(位置情報), Epinions(SNS), BookX(本）, AMZe(EC)各データセットのどのバージョンを利用するかも、権威性、情報量を考慮し選定した前処理明示的フィードバック(評価やカウント）を、暗黙的フィードバックに二値化しているがやり方に多様性がある$U, I$ をユーザ、アイテムとして、$r_{ui}$を$U$の$I$に対する二値フィードバックとする$r_{ui}$ は、しきい値以上の明示的フィードバックがあれば１、なければ０としたしきい値は論文によって設定に多様性があったが、ML-1Mでは4、それ以外は1としたほとんどのユーザは5個以下のアイテムにしか評価を行っていないため、アクティブでないユーザを弾く前処理を入れることがある約50%の論文でアクティブでないユーザを弾く前処理を採用していたこのうち60%以上の論文で5,10回以上のユーザのみ扱う戦略を採用していたそれ以外の回数にしきい値を設定した論文もあった本研究では、オリジナル, 5-filter(5回以上評価したユーザのみ）, 10-filterを採用したK-filterはK-coreとは異なるK-filter: 評価及び被評価数で一回だけ、ユーザとアイテムをフィルタリングする K-core: すべてのユーザ/アイテムがK回の評価を与える/受けるようになるまでフィルタリングをする27%はオリジナルをそのまま、23%はどのような処理が行われたか公開されていなかった比較手法fig1(c)は比較手法の分布上位10位内の比較手法で全体の93%の論文をカバーしているメモリベース(MM)MostPop: 人気度上位のアイテムを全員に推薦ItemKNN: アイテム類似度(ここではcos)を定義し、K-NNベースで推薦潜在因子ベース(LFM)BPRMF: 行列分解を用いて、BPR(Bayesian Personalized Ranking)損失を最小化するBPRFM: Factorization Machine系でユーザ、アイテム間の二次の特徴まで考慮PureSVD: ユーザアイテム行列に対して単純にSVDを適用SLIM: 制約項つきの二乗損失を、分解再構成した行列に対して適用表現学習ベース(RLM)NeuMF: 行列分解の潜在ベクトル積のGMFとMLPを結合して回帰する深層推薦アルゴリズム目的関数目的関数には大きく分けて２タイプが利用されているpoint-wise (収集された論文の49%が採用)アイテムへの嗜好を点で数値として予測し、その精度を測るpoint-wiseの損失では、クロスエントロピーや二乗誤差がよく使われる今回はTOPN推薦なので二乗誤差は評価しなかったpair-wise (収集された論文の42%が採用）アイテムのペアの順序を予測し、相対的な順序を考慮することで、順位損失を近似するpair-wiseの損失では、対数損失やヒンジロスがよく使われる負例のサンプリング観測はランダムにおきるわけではない（人気などと相関がある）ので、観察されたデータのみで評価するのはTOPN推薦には不適当非観測の部分をどう評価するかが重要本研究では、多くの研究を踏襲して観測されないフィードバッグを負例のフィードバッグとして扱う本来、観測されないデータに関して、異なる解釈も可能なことは注意したい未観測部分を適切に活用することを考える実際、70%の論文で目的関数を設計するときに、未観測部分について、フィードバックとして考慮している本研究で検証したサンプル戦略一様サンプラー収集したほとんどの論文で採用されているアイテムの人気度ベースのサンプラー低人気度サンプラー欠測部のうち、人気度が低いアイテムに関して積極的に負例として採用する人気の低いアイテムを好む可能性が低いという仮説に基づく高人気度サンプラー欠測部のうち、人気度が高いアイテムに関して積極的に負例として採用する人気の高いアイテムに関して、ユーザがフィードバックしていない場合、本当に低評価の可能性が高いという仮説に基づくデータ分割法主に二種類の方法が存在した。split-by-ratio (61%の論文が採用）一定割合ρを学習、残りの1-ρを評価に使う方法。実際は以下の観点で多様性があった。比率学習の割合が50%-90%まで様々分割粒度ユーザを最小単位として分割するものフィードバック一つ一つを最小単位として分割するもの(同一ユーザのデータが学習と評価に分かれることもある）ランダムか、時系列を考慮しているか学習データはすべてテストデータ以前に発生したデータになっているかどうか12%が時系列を考慮した分割をしていたleave-one-out (28%の論文が採用）ユーザごとに一つのデータだけをテスト用に保存しておき、残りを学習に使う分割粒度たいていユーザ単位ランダムか、時系列を考慮しているかLOOのうち54%は時系列を考慮していたその他、5%は特定時刻で分割, 残り6%はデータ分割について無記載評価指標評価指標は収集した論文の中で、分散が大きい項目94%が6つの手法のうちどれかを利用していた(Fig1 (d))計測に使った指標上位リスト内に含まれるか計測PrecisionRecallMean Average Precision(MAP)Precision@k / sum_k の平均Hit Ratio(HR)順位を計測Mean Reciprocal Rank(MRR)順位の逆数の平均Normalized Discounted Cumlative Gain (NDCG)スコアを順位の対数逆数で割り引くハイパーパラメータ探索ハイパーパラメータ探索は、最終的な性能に大きく影響を与える。実験設定としては、どのようにデータセットを分割するか、どのように探索するか、という要素があった。分割戦略37%の論文がテストセットの性能を見ながら、ハイパーパラメータを調整していることがわかったこれはテストデータの情報がモデルに漏れて、過学習を起こす可能性があるnested validationによって回避できる学習とテストの他に、ハイパーパラメータ用の検証セットを用意する方法本研究では、学習セットからさらにその10%を検証セットとしてとっておくnested validationを採用したハイパーパラメータを検証セットによって設定した後、元々の学習データをすべて投入させ再学習させた探索戦略ほとんどの論文でグリット探索を利用していたグリット探索はパラメータが少ないモデル向きで、そうでないと組合せ爆発を起こすパラメータ$m$個が$n$個の値をとれると、$m^n$通りの組合せが存在するBayesian Hyper Optはランダムよりも賢い手法本研究ではNDCGに対して、Bayesian Hyper Optを採用した過去の試行を生かしてパラメータを探索するため、randomより効率的特に指定がなければ、本論文では以下の設定を採用しているハイパーパラメータ探索時の指標NDCG分割方法Nested validation学習データの10%を利用探索方法Bayesian Hyper Opt比較実験評価項目アルゴリズムデータセット前処理損失関数負例のサンプリング法データ分割評価指標データセット比較要素ML1M(映画), Lastfm(音楽), Yelp(位置情報), Epinions(SNS), BookX(本), AMZe(EC)結果アルゴリズムと合わせて後述アルゴリズム比較要素メモリベース(MM)MostPop, ItemKNN潜在因子ベース(LFM)BPRMF, BPRFM, PureSVD, SLIM表現学習ベース(RLM)NeuMF結果ほとんどでMostpopが一番悪く、パーソナライズの効果を示している(Fig2)ML-1Mにおいては、ItemKNN, SVD, BPRMFに勝っており、データセット次第では有効LastFMではItemKNNは、LFM、DFMに勝っている近傍ベースの考え方を取り入れることでよくなるかも？NeuMFはML-1M, AMZeでは健闘してるが、他は負けているDLMがパラメータを最適化した既存手法に勝てるわけではない訓練コストが高いのもネック10-filterで固定すると(Table4の設定), BPRFMが少しよさそうか？前処理比較要素original5-filter, 10-filter評価数N以上のユーザのみ扱う結果ユーザあたりの平均評価量の増減と相関している密度があがるものは向上、減るものは減少する(密度：Table2b, 性能: Fig2)ML-1Mでは影響なしYelp, BookX, AMZeはフィルターするほど性能向上Lastfm, Epinionsは性能低下損失関数比較要素point-wiseクロスエントロピー(CE)pair-wise対数損失(LL)ヒンジ損失(HL)結果分析Pair-wise+LogLoss(赤)が総じて優れている(Fig3)BPRFM(中)は目的関数に対する感度が低くロバスト負例のサンプリング法比較要素未評価を負例としてサンプリングして使う一様サンプラー低人気度サンプラー(Lpop)高人気度サンプラー(Hpop)結果一様サンプラー（灰）が最も優れている(Fig4)Lpop(赤）の方が不人気なアイテムを負例として扱うため良さそうだが、直感に反する結果 データ分割比較要素split-by-ratio(学習:テスト＝80:20)ランダム分割時系列を考慮した分割結果ほとんどのデータセットでランダムが有利とくにEpnions(SNS)ではランダムが３倍ほど有利になった(Fig5 (c))実際のシナリオに近いのは時系列分割ランダム分割による検証は実環境より、過大評価されている可能性がある評価指標比較要素ある指標を最適化するハイパーパラメータが、別の指標でも最適とは限らない指標xベースラインごとに30回試行して、ある指標において最良な試行をとりだすそれが、別の指標においても最良であれば、その指標間で得点1、相関係数は総得点を試行回数で割ったもの6つの手法x6つのデータセットで全部で36で得点を割る異なる指標で最適化された時の、推薦されるアイテムのKendall順序相関もみた計測に使った指標一定順位内に含まれるかどうかを計測Precision, Recall, MAP, HR 順位を計測MRR, NDCG結果ある指標を最適化するハイパーパラメータが、別の指標でも最適というわけではなかった(Fig:5-e)相関行列は非対称NDCG-\u003eHRは0.72, HR-\u003eNDCGは0.64Kendall順序相関においては、Recallが著しく他の指標と異なることがわかった(Fig:5-f)比較実験から得られた結論 (@smochiの解釈)大前提、データの性質に左右されやすいが、以下のような解釈。アルゴリズムデータによって異なる、BPRFMがやや強い必ずしも複雑なモデルが強いわけではない(e.g. NeuMF)前処理ユーザごとのデータ密度が上がるならやった方がよい損失関数Pair-wise+LogLossが第一選択か負例のサンプリング法一様サンプラーが第一選択かデータ分割グローバルで学習:テスト=80:20時系列は考慮して分割すべき評価指標指標ごとに強いモデルが異なり、相関も低かったりするので実際の状況に近い指標を選択すべき","link":"https://qiita.com/smochi/items/c4cecc48e4aba0071ead","isoDate":"2020-10-25T16:09:35.000Z","dateMiliSeconds":1603642175000,"authorName":"smochi","authorId":"smochi"},{"title":"RecSys 2019 ベストペーパーを読んだメモ","contentSnippet":"紹介論文Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches (RecSys 2019)日本語では「本当にそんなに進捗出てるの？ -或いは最近のNN推薦手法に対する警鐘-」という感じだろうか。元論文はこちら https://arxiv.org/pdf/1907.06902.pdf概要DNNが登場してから推薦分野でもDeepXXな手法が増えている新手法の登場頻度が高いため、代表的なタスクであるtopN推薦に対してすらSOTAが何か追えなくなっているそこでトップ会議（KDD, SIGIR, WWW, RecSys）のDNN関連研究18本を追試した18本のうち、現実的な努力を行った上で再現できたのが7本（RecSysでの発表によると、）実装が再現できない場合は、実装を原著者らに問い合わせて1ヶ月待ったさらに6/7がkNNベース＋ハイパーパラメータ最適化に負けてしまった残りの1つもDNNではない線形の手法を調整したものに負ける場合もあったこのような問題の原因として、筆者らは以下を主張している再現性の低さ実装, 前処理, ハイパラの再現が難しい実験設定、実装が疑わしいものもある正しいベースラインとの比較が行われていないドメインでの調整が行われたkNNなどのシンプル（だが強力）な手法との比較がされてないあらゆる古典的手法に敗北している手法もある評価方法以下にこの論文で行ったすべての実験の再現のコードやデータ、ハイパラの設定などが格納されている。https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation評価手法は以下論文で行われたものと同様の手法を利用。https://arxiv.org/pdf/1803.09587.pdf比較対象とした古典的手法TopPopular名前の通り、全員に同一の最も平均レーティングの高いアイテムを推薦1 ItemKNNKNNとアイテム間類似性をベースとした協調フィルタリング（CF）の手法。$r_{i}, r_{j}$は暗黙的(implicit)な評価値$h$はユーザからの評価回数が少ないアイテムの登場時に下駄を履かせる定数TF-IDFやBM25で傾斜をかけることもある残りのハイパーパラメータとしてk近傍の$k$アイテム$i$と$j$の間のコサイン類似度$s_{ij}$を以下で定義s_{i j}=\\frac{\\mathbf{r}_{i} \\cdot \\mathbf{r}_{j}}{\\left\\|\\mathbf{r}_{i}\\right\\|\\left\\|\\mathbf{r}_{j}\\right\\|+h}2 UserKNNItemKNNと似た評価方法で、User間類似性をベースとした手法。ハイパーパラメータはItemKNNと同様。3 ItemKNN-CBF1, 2の手法が評価値ベースの手法であるのに対して、コンテンツ（特徴量）ベースの代表的手法。$\\mathbf{f}_{i}, \\mathbf{f}_{j}$ はアイテムに付与される特徴量ベクトル残りの変数、ハイパーパラメータは1, 2と同様アイテム$i$と$j$の間のコサイン類似度$s_{ij}$を以下で定義s_{i j}=\\frac{\\mathbf{f}_{i} \\cdot \\mathbf{f}_{j}}{\\left\\|\\mathbf{f}_{i}\\right\\|\\left\\|\\mathbf{f}_{j}\\right\\|+h}4 ItemKNN-CFCBF1, 3のハイブリッド的手法。3の特徴量 $\\mathbf{f}$ に評価値の次元を加えるただし、そのまま次元を結合するのではなく、特徴量に重み$w$をつけて $[\\mathbf{r}_{i}, w\\mathbf{f}_{i}]$とする5 P3αユーザとアイテム間で定義されたグラフ上でランダムウォークを行うことで、アイテムのランク付けを行う手法らしい。ユーザ$u$からアイテム$i$にジャンプする確率は$p_{ui}=(r_{ui} / N_{u})^\\alpha$で表現同様にアイテム$i$からユーザ$u$にジャンプする確率は$p_{iu}=(r_{ui} / N_{i})^\\alpha$で表現$N_{i}$, $N_{u}$はそれぞれ、アイテム、ユーザの被評価、評価の回数$\\alpha$は減衰係数アイテムベースのCFと同じ様に扱うことができ、類似度 $s_{ij}$は以下で定義されるs_{i j}=\\sum_{v} p_{j v} p_{v i}ハイパーパラメータはkNNの$k$と減衰係数$\\alpha$コストパフォーマンスが良い、筆者推しの手法らしい6 RP3β5の亜種。類似度$s_{ij}$の計算の際に、$s_{ij}$を各アイテムの人気度に係数$\\beta$を累乗したもので割って人気度を正規化する。$\\beta=0$で5と等価。再現できたので評価した手法Collaborative Memory Networks (CMN)  Metapath based Context for RECommendation (MCRec)  Collaborative Variational Autoencoder (CVAE)  Collaborative Deep Learning (CDL)  Neural Collaborative Filtering (NCF)  Spectral Collaborative Filtering (SpectralCF)  Variational Autoencoders for Collaborative Filtering (Mult-VAE)  各手法の評価7 Collaborative Memory Networks (CMN) メモリーネットワークとアテンションを潜在因子に組み合わせた手法原著の実験 行列分解、NNベース、ItemKNN($h$なし)と比較 Epinions、CiteULike-a、Pinterestのデータセット 比較手法のハイパーパラメータ最適化に関する記述なし今回の実験ヒット率(HR@5)で比較手法のハイパーパラメータを最適化結論原著では比較手法に比べCMN全勝だったが、ほとんど勝てなくなってしまったEpinionsに至っては最も単純なTopPopularが圧勝このデータセットはGini指数が0.69と人気が偏ってるのが原因か8 Metapath based Context for RECommendation (MCRec) 映画のジャンルなどの補助情報を活用するメタパスベースのモデル。優先度つきサンプリングを用いて良いパスを選択。新しいアテンション手法も提案している。原著の実験 MovieLens100k, LastFm, Yelpの比較的小さいデータセット 80/20の分割を10回平均で評価 比較手法のハイパーパラメータ最適化に関する記述が一部ない NDCGの評価値が怪しい今回の実験原著と同じく精度で比較手法のハイパーパラメータを最適化結論すべての評価指標でItemKNNに敗北原著の比較手法のハイパーパラメータは異なるデータに最適化されていて弱体化していた提供された実装を調べたところ、各指標を別のバリデーションセットで一番良かった指標を記載していて、不適切9 Collaborative Variational Autoencoder (CVAE) 教師なしでアイテム特徴から深い潜在表現を学習し、コンテンツと評価の両方からアイテムとユーザー間の暗黙的な関係を学習する手法。原著の実験 CiteULike(135k, 205k回評価)の比較的小さいデータセット 異なる推薦リスト長（50, 100, 300)でのリコールが評価指標 ランダムな学習-評価のバリデーションセットが作られ5回評価 データセットと評価方法がコードベースで共有されている今回の実験原著と同じくリコールで比較手法のハイパーパラメータを最適化結論すべてのリスト長でItemKNN-CFCBFに敗北CVAEは提案リスト長が長くなると強くなったが、それは原著の対象としてはあまり良い状況ではない10 Collaborative Deep Learning (CDL) Stacked Denoising AutoEncoders(SDAE)とCollaborative Topic Regression(CTR)を同時に解くモデル。CTRのトピック表現にSDAEを適用し、より低次元の表現をしたものでCTRを行っている気がする。CVAEの手法でベースラインとして引用された。原著の実験 CVAEと同様の実験設定 CTRと比べスパースなデータの状況で強いことを主張今回の実験原著と同じくリコールで比較手法のハイパーパラメータを最適化(原著は疎な状況の優位さを主張しているが）高密度の設定で評価結論すべての推薦リスト長で複数の古典的手法に敗北推薦リスト長が短いと性能がかなり悪い（ちなみに）9のCVAEと比較するとたしかにCVAEはCDLよりは良くなってるが、結局古典的手法には勝っていない11 Neural Collaborative Filtering (NCF) CFで使われる行列分解と、その内積表現の部分をNNベースの関数に置き換えてデータから学習するモデル。原著の実験 MovieLens1M(100万回評価)とPinterest（150万回評価）で実験 Leave-one-outを使ってデータを分割 ヒット率とNDCGを$@$5, $@$10で評価 既存の行列分解よりも優位なことを主張今回の実験原著実装ではテストセットを使ってエポック数を調節していたため、不適切。今回は学習セットでエポック数を最適化原著ではItemKNNのハイパーパラメータを$k$のみ調節していたが、今回はすべてを最適化シンプルな線形手法であるSLIMを比較手法として用意結論すべての指標で複数の古典的手法に敗北MovieLensでは線形手法であるSLIMにすべての指標で敗北12 Spectral Collaborative Filtering (SpectralCF) コールドスタート問題を解決するために、スペクトラルグラフ理論をベースに作られたモデル。ユーザーアイテム間の二部グラフをグラフフーリエ変換で畳み込むらしい。原著の実験 MovieLens1M, HetRec, Amazon Instant Videoで実験 バリデーションは80/20で学習とテストを分割 いくつかのカットオフでリコールとMAPを測定 MovieLensで筆者が学習とテストに使用したデータセットが公開されている 原著ではあるデータセットで決定した（おそらく比較手法の）ハイパーパラメータをすべてのデータセットに適用している（！）今回の実験原著の設定はおかしいので、それぞれのデータセットでハイパーパラメータを最適化しなおした結論すべての指標ですべての古典的手法に敗北（！！）が、原著で提供されたデータセットで実験すると何故かすべての比較手法に圧勝する…  筆者が調べたところ、原著データは明らかにランダムサンプリングされたものと異なる分布を示すデータ分割になっていた本来は人気アイテムが偏っているが、提供されたデータのテストセットはなぜか偏りが抑制されていた…人気度分布の異常な差を示した図13 Variational Autoencoders for Collaborative Filtering (Mult-VAE) 変分オートエンコーダー(VAE)を使った暗黙的なフィードバックを利用するCF。多項尤度を持つ生成モデルを導入し、学習対象に対して異なる正則化項を設定して、ベイズ推論によってパラメータを推定する手法らしい。原著の実験 映画の評価(おそらくMovieLens)や歌の再生回数を二値化して利用 実装とデータセットが提供され、行列分解、線形モデル、NNベースの手法と比較 リコール(at20, at50)とNDCG(at100)を指標として、比較手法より3%ほど優れた結果になっている今回の実験Netflixで良い性能をだしたSLIMも比較手法に追加して、非NN手法よりも優位であるという主張を検証することにした結論比較手法として用意したすべての古典的手法に対して各指標で10%〜20%ほど優れていた  ただし、SLIMに対してはあまり大きな差はみられなかったとくにNDCG@100はほとんど差はないカットオフの値が一定でない(REC@(20or50), NDCG@100)ため、リコールとNDCGのカットオフの値を揃えて実験したすると、原著に記載されてなかったREC@100, NDCG@100ではSLIMが優位だったつまりNNの導入により、非NN手法より性能が向上したという主張は検証できなかったSLIMとの比較DNN推薦における問題点スケーラビリティと再現性再現性が低すぎる論文を読んで再現できた手法が7/18しかない再現できたものに関しても、ハイパラやデータの前処理、評価方法などが開示されてないものがあり再現が難しい計算コストが高すぎ、スケーラビリティがない数年前はNetflixの100Mデータセットで検証することが業界標準だったが、いまは100Kで許される100KですらGPUを使ってもハイパラの最適化に数日〜数週間かかる手法もあるためか？(RecSysでの発表によると、)筆者らもすべてのDNN実験を再現するために、253日もAWSを使い倒した… kNNもスケーラビリティ問題はあるが、適切なサンプリングにより対処できる改善幅の計測比較したベースラインに関する詳細な情報が提供されてない本当に適切な最適化や前処理を行ったのか検証できないベースラインに対するデータ分割、評価手段、実装に関して間違いのある論文も発見したDNN手法の比較相手になりがちなNCFは本当に強いのか？NCFはあるデータセットではシンプルな手法に負けており、他のデータセットでも圧勝しているわけではない線形回帰にさえ負けるデータセットもある評価データセットと評価指標が多すぎて比較できない世の中には20種類以上の公開データセットがあるが、だいたい適当に1,2個を選んで実験しているたくさんの評価指標Precision, Recall, MAP, NDCG, MRRたくさんのバリデーション方法random holdout 80/20, leave-last-out, leave-one-out, 100 negative items or 50 negative items for each positivetopNといっても色々な評価方法があるN位までにできるだけ多くの関連アイテムを出す1つのアイテムが上位に入れば入るほどよいMovieLensの評価値の予測指標が改善したからと言って、(他の種類の)推薦タスクの体験が改善するわけではない今後の進展行列分解をベースとしたアルゴリズム全般にも同じ実験をやっていきたい( 本当にありがたいことです)感想最近、推薦分野もNNでどんどん進捗でてるなと、ちゃんと再現実験もせずに思っていたので衝撃を受けました…。この論文を執筆するための筆者らの多大な努力を感じました。素晴らしい仕事です。すべてが実装、データ、条件付きで公開され、こういう論文がベストペーパーに選ばれるのは当然だし素晴らしいことだと思いました。","link":"https://qiita.com/smochi/items/98dbd9429c15898c5dc7","isoDate":"2019-09-16T16:13:59.000Z","dateMiliSeconds":1568650439000,"authorName":"smochi","authorId":"smochi"}]},"__N_SSG":true},"page":"/members/[id]","query":{"id":"smochi"},"buildId":"zdxNTCoN0tI9JUsRuPa5g","nextExport":false,"isFallback":false,"gsp":true,"head":[["meta",{"name":"viewport","content":"width=device-width"}],["meta",{"charSet":"utf-8"}],["link",{"rel":"icon shortcut","type":"image/png","href":"https://blog.ubie.tech/logo.png"}],["link",{"rel":"stylesheet","href":"https://fonts.googleapis.com/css2?family=Inter:wght@400;700\u0026display=swap"}],["title",{"children":"smochi | Ubie Engineers' Blogs"}],["meta",{"property":"og:title","content":"smochi"}],["meta",{"property":"og:url","content":"https://blog.ubie.tech/members/smochi"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"property":"og:site","content":"Ubie Engineers' Blogs"}],["meta",{"property":"og:image","content":"https://blog.ubie.tech/og.png"}],["link",{"rel":"canonical","href":"https://blog.ubie.tech/members/smochi"}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-fa276ba060a4a8ac7eef.js"></script><script src="/_next/static/chunks/main-8a83f0fd99327c4684a8.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/framework.1daf1ec1ecf144ee9147.js" async=""></script><script src="/_next/static/chunks/commons.8d61253ae98ee51657b8.js" async=""></script><script src="/_next/static/chunks/pages/_app-49079e3278dd6cef7229.js" async=""></script><script src="/_next/static/chunks/81b50c7ab23905e464b4340eb234bd6ea389d26b.83ad1c2705ae70f873e8.js" async=""></script><script src="/_next/static/chunks/pages/members/%5Bid%5D-f279413a3daf3c18264d.js" async=""></script><script src="/_next/static/zdxNTCoN0tI9JUsRuPa5g/_buildManifest.js" async=""></script><script src="/_next/static/zdxNTCoN0tI9JUsRuPa5g/_ssgManifest.js" async=""></script></body></html>